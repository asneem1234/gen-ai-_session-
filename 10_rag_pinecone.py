"""
10 - RAG with Pinecone Vector Database
========================================

This module demonstrates building production-ready RAG with Pinecone.
Students will learn:
- What vector databases are
- Setting up Pinecone
- Indexing documents at scale
- Efficient similarity search
- Production RAG patterns
- Metadata filtering
- Scaling considerations

Teaching Points:
- Vector databases enable efficient large-scale RAG
- Pinecone handles indexing and search infrastructure
- Essential for production applications
- Much more scalable than basic implementations
"""

import os
from dotenv import load_dotenv
import google.generativeai as genai
from typing import List, Dict
import time

# Setup
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))


# ============================================================================
# SECTION 1: Understanding Vector Databases
# ============================================================================

def vector_database_concepts():
    """
    Explain vector databases and why they're needed
    """
    print("\n" + "=" * 60)
    print("SECTION 1: Understanding Vector Databases")
    print("=" * 60)
    
    explanation = """
    üóÑÔ∏è WHAT ARE VECTOR DATABASES?
    
    Traditional Database:
    ‚Ä¢ Stores structured data (rows, columns)
    ‚Ä¢ Searches by exact match or ranges
    ‚Ä¢ Example: Find users where age > 25
    
    Vector Database:
    ‚Ä¢ Stores high-dimensional vectors (embeddings)
    ‚Ä¢ Searches by similarity
    ‚Ä¢ Example: Find documents similar to query vector
    
    
    ‚ùå BASIC RAG LIMITATIONS:
    
    1. Scale Issues
       ‚Ä¢ Slow with 1000+ documents
       ‚Ä¢ All embeddings in memory
       ‚Ä¢ Linear search O(n)
    
    2. No Persistence
       ‚Ä¢ Recompute embeddings each run
       ‚Ä¢ No efficient updates
       ‚Ä¢ Can't handle millions of docs
    
    3. No Advanced Features
       ‚Ä¢ No metadata filtering
       ‚Ä¢ No hybrid search
       ‚Ä¢ No distributed architecture
    
    
    ‚úÖ VECTOR DATABASE BENEFITS:
    
    1. Performance
       ‚Ä¢ Approximate Nearest Neighbor (ANN) search
       ‚Ä¢ Sub-millisecond queries
       ‚Ä¢ Scales to billions of vectors
    
    2. Persistence
       ‚Ä¢ Durable storage
       ‚Ä¢ Easy updates/deletes
       ‚Ä¢ Version control
    
    3. Advanced Features
       ‚Ä¢ Metadata filtering
       ‚Ä¢ Namespaces for organization
       ‚Ä¢ Real-time updates
       ‚Ä¢ Distributed architecture
    
    4. Production Ready
       ‚Ä¢ High availability
       ‚Ä¢ Monitoring & analytics
       ‚Ä¢ Security features
       ‚Ä¢ API access
    
    
    üèÜ POPULAR VECTOR DATABASES:
    
    1. Pinecone üå≤
       ‚Ä¢ Fully managed (cloud)
       ‚Ä¢ Easy to use
       ‚Ä¢ Great performance
       ‚Ä¢ Free tier available
    
    2. Weaviate
       ‚Ä¢ Open source
       ‚Ä¢ Rich features
       ‚Ä¢ Self-hosted or cloud
    
    3. Qdrant
       ‚Ä¢ Rust-based
       ‚Ä¢ Fast
       ‚Ä¢ Open source
    
    4. Milvus
       ‚Ä¢ Open source
       ‚Ä¢ Enterprise features
       ‚Ä¢ Large scale
    
    5. Chroma
       ‚Ä¢ Embedded database
       ‚Ä¢ Great for development
       ‚Ä¢ Python-first
    
    
    üéØ WHEN TO USE VECTOR DATABASES:
    
    Use Vector DB when:
    ‚Ä¢ 1000+ documents
    ‚Ä¢ Production application
    ‚Ä¢ Need fast queries
    ‚Ä¢ Frequent updates
    ‚Ä¢ Multiple users
    
    Basic RAG sufficient for:
    ‚Ä¢ Small document sets
    ‚Ä¢ Prototyping
    ‚Ä¢ Learning
    ‚Ä¢ Single-user apps
    
    
    üìä PINECONE ARCHITECTURE:
    
    Your App ‚Üí Pinecone API ‚Üí Pinecone Index
                                  ‚Üì
                              Vector Storage
                                  ‚Üì
                            ANN Search Engine
                                  ‚Üì
                            Returns Results
    
    Pinecone handles:
    ‚Ä¢ Storage
    ‚Ä¢ Indexing
    ‚Ä¢ Search optimization
    ‚Ä¢ Scaling
    ‚Ä¢ High availability
    """
    
    print(explanation)


# ============================================================================
# SECTION 2: Pinecone Setup
# ============================================================================

def pinecone_setup_guide():
    """
    Guide for setting up Pinecone
    """
    print("\n" + "=" * 60)
    print("SECTION 2: Pinecone Setup Guide")
    print("=" * 60)
    
    guide = """
    üìù SETUP STEPS:
    
    1. CREATE ACCOUNT
    ==================
    ‚Ä¢ Visit: https://www.pinecone.io/
    ‚Ä¢ Sign up for free tier
    ‚Ä¢ No credit card required for starter
    
    Free Tier Includes:
    ‚Ä¢ 1 index
    ‚Ä¢ 100K vectors (768 dims)
    ‚Ä¢ Good for learning & prototyping
    
    
    2. GET API KEY
    ==============
    ‚Ä¢ Dashboard ‚Üí API Keys
    ‚Ä¢ Copy your API key
    ‚Ä¢ Copy your environment (e.g., "us-east-1-aws")
    
    
    3. INSTALL LIBRARY
    ==================
    pip install pinecone-client
    
    
    4. CONFIGURE ENVIRONMENT
    ========================
    Add to .env file:
    
    PINECONE_API_KEY=your_api_key_here
    PINECONE_ENVIRONMENT=your_environment_here
    
    
    5. VERIFY SETUP
    ===============
    Run the connection test in this module!
    
    
    üíª BASIC CODE STRUCTURE:
    
    from pinecone import Pinecone, ServerlessSpec
    
    # Initialize
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    
    # Create index
    pc.create_index(
        name="my-index",
        dimension=768,  # Match your embedding size
        metric="cosine",
        spec=ServerlessSpec(
            cloud="aws",
            region="us-east-1"
        )
    )
    
    # Connect to index
    index = pc.Index("my-index")
    
    # Upsert vectors
    index.upsert(vectors=[
        ("id1", [0.1, 0.2, ...], {"text": "content"})
    ])
    
    # Query
    results = index.query(
        vector=[0.1, 0.2, ...],
        top_k=5,
        include_metadata=True
    )
    
    
    ‚öôÔ∏è KEY CONCEPTS:
    
    ‚Ä¢ Index: Container for vectors
    ‚Ä¢ Dimension: Size of your embeddings
    ‚Ä¢ Metric: cosine, euclidean, or dotproduct
    ‚Ä¢ Namespace: Logical partition within index
    ‚Ä¢ Metadata: Additional info stored with vectors
    """
    
    print(guide)
    
    # Test connection
    print("\n\nüîå CONNECTION TEST:")
    print("-" * 60)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ùå PINECONE_API_KEY not found in .env file")
            print("\nüí° To use this module:")
            print("   1. Sign up at pinecone.io")
            print("   2. Get your API key")
            print("   3. Add to .env file")
            return False
        
        # Initialize
        pc = Pinecone(api_key=api_key)
        
        # List indexes
        indexes = pc.list_indexes()
        
        print("‚úÖ Connected successfully!")
        print(f"üìä Existing indexes: {len(indexes.indexes)}")
        
        for idx in indexes.indexes:
            print(f"   ‚Ä¢ {idx.name}")
        
        return True
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
        print("   Run: pip install pinecone-client")
        return False
    except Exception as e:
        print(f"‚ùå Connection error: {e}")
        return False


# ============================================================================
# SECTION 3: Creating a Pinecone Index
# ============================================================================

def create_pinecone_index():
    """
    Create and configure a Pinecone index
    """
    print("\n" + "=" * 60)
    print("SECTION 3: Creating a Pinecone Index")
    print("=" * 60)
    
    try:
        from pinecone import Pinecone, ServerlessSpec
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ö†Ô∏è  Pinecone API key not configured")
            print("   This section requires a Pinecone account")
            return
        
        pc = Pinecone(api_key=api_key)
        
        index_name = "rag-demo-index"
        
        print(f"\nüìù Creating index: {index_name}")
        print("-" * 60)
        
        # Check if index already exists
        existing_indexes = [idx.name for idx in pc.list_indexes().indexes]
        
        if index_name in existing_indexes:
            print(f"‚ÑπÔ∏è  Index '{index_name}' already exists")
            print("   Deleting and recreating...")
            pc.delete_index(index_name)
            time.sleep(1)  # Wait for deletion
        
        # Create index
        print("\n‚è≥ Creating index...")
        print(f"   ‚Ä¢ Name: {index_name}")
        print(f"   ‚Ä¢ Dimension: 768 (Gemini embedding size)")
        print(f"   ‚Ä¢ Metric: cosine")
        print(f"   ‚Ä¢ Cloud: AWS")
        
        pc.create_index(
            name=index_name,
            dimension=768,  # Gemini embedding dimension
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )
        
        print("\n‚úÖ Index created successfully!")
        print("\nüí° Index configuration:")
        print("   ‚Ä¢ Serverless: Scales automatically")
        print("   ‚Ä¢ Cosine similarity: Best for text embeddings")
        print("   ‚Ä¢ Ready to use immediately")
        
        # Wait for index to be ready
        print("\n‚è≥ Waiting for index to be ready...")
        time.sleep(5)
        
        # Get index stats
        index = pc.Index(index_name)
        stats = index.describe_index_stats()
        
        print("\nüìä Index Stats:")
        print(f"   ‚Ä¢ Total vectors: {stats['total_vector_count']}")
        print(f"   ‚Ä¢ Dimension: {stats['dimension']}")
        
        return index_name
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
        print("   Run: pip install pinecone-client")
    except Exception as e:
        print(f"‚ùå Error creating index: {e}")


# ============================================================================
# SECTION 4: Indexing Documents
# ============================================================================

def index_documents():
    """
    Index documents into Pinecone
    """
    print("\n" + "=" * 60)
    print("SECTION 4: Indexing Documents")
    print("=" * 60)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ö†Ô∏è  Pinecone API key not configured")
            return
        
        pc = Pinecone(api_key=api_key)
        index_name = "rag-demo-index"
        
        # Check if index exists
        existing_indexes = [idx.name for idx in pc.list_indexes().indexes]
        
        if index_name not in existing_indexes:
            print(f"‚ö†Ô∏è  Index '{index_name}' not found")
            print("   Run Section 3 to create it first")
            return
        
        index = pc.Index(index_name)
        
        # Sample documents
        documents = [
            {"id": "doc1", "text": "Python is a high-level programming language created by Guido van Rossum.", "category": "intro"},
            {"id": "doc2", "text": "Python emphasizes code readability with significant indentation.", "category": "syntax"},
            {"id": "doc3", "text": "Django is a popular web framework for Python.", "category": "frameworks"},
            {"id": "doc4", "text": "Flask is a lightweight web framework for Python.", "category": "frameworks"},
            {"id": "doc5", "text": "NumPy provides support for large multi-dimensional arrays.", "category": "data-science"},
            {"id": "doc6", "text": "Pandas is used for data manipulation and analysis.", "category": "data-science"},
            {"id": "doc7", "text": "Scikit-learn is a machine learning library for Python.", "category": "ml"},
            {"id": "doc8", "text": "TensorFlow and PyTorch are deep learning frameworks.", "category": "ml"},
            {"id": "doc9", "text": "Python has a large standard library included by default.", "category": "features"},
            {"id": "doc10", "text": "Python supports multiple programming paradigms.", "category": "features"}
        ]
        
        print(f"\nüìö Indexing {len(documents)} documents...")
        print("-" * 60)
        
        # Generate embeddings and prepare for upsert
        vectors_to_upsert = []
        
        for doc in documents:
            print(f"   Processing: {doc['id']}")
            
            # Generate embedding
            result = genai.embed_content(
                model="models/embedding-001",
                content=doc['text'],
                task_type="retrieval_document"
            )
            embedding = result['embedding']
            
            # Prepare vector with metadata
            vectors_to_upsert.append({
                "id": doc['id'],
                "values": embedding,
                "metadata": {
                    "text": doc['text'],
                    "category": doc['category']
                }
            })
        
        # Upsert to Pinecone
        print("\n‚è≥ Uploading to Pinecone...")
        index.upsert(vectors=vectors_to_upsert)
        
        print("‚úÖ Upload complete!")
        
        # Wait for indexing
        time.sleep(2)
        
        # Get stats
        stats = index.describe_index_stats()
        print(f"\nüìä Index now contains {stats['total_vector_count']} vectors")
        
        return True
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
    except Exception as e:
        print(f"‚ùå Error indexing documents: {e}")
        return False


# ============================================================================
# SECTION 5: Querying Pinecone
# ============================================================================

def query_pinecone():
    """
    Search the Pinecone index
    """
    print("\n" + "=" * 60)
    print("SECTION 5: Querying Pinecone")
    print("=" * 60)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ö†Ô∏è  Pinecone API key not configured")
            return
        
        pc = Pinecone(api_key=api_key)
        index = pc.Index("rag-demo-index")
        
        # Test queries
        queries = [
            "Who created Python?",
            "What frameworks can I use for web development?",
            "Tell me about data science libraries"
        ]
        
        for query in queries:
            print(f"\n{'='*60}")
            print(f"üîç Query: '{query}'")
            print(f"{'='*60}")
            
            # Generate query embedding
            query_result = genai.embed_content(
                model="models/embedding-001",
                content=query,
                task_type="retrieval_query"
            )
            query_embedding = query_result['embedding']
            
            # Search Pinecone
            print("\n‚è≥ Searching Pinecone...")
            
            results = index.query(
                vector=query_embedding,
                top_k=3,
                include_metadata=True
            )
            
            # Display results
            print(f"\n‚úÖ Found {len(results['matches'])} matches:\n")
            
            for i, match in enumerate(results['matches'], 1):
                score = match['score']
                text = match['metadata']['text']
                category = match['metadata']['category']
                
                print(f"{i}. [Score: {score:.4f}] [Category: {category}]")
                print(f"   {text}\n")
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
    except Exception as e:
        print(f"‚ùå Error querying: {e}")


# ============================================================================
# SECTION 6: Complete RAG with Pinecone
# ============================================================================

def complete_rag_pinecone():
    """
    Full RAG pipeline using Pinecone
    """
    print("\n" + "=" * 60)
    print("SECTION 6: Complete RAG Pipeline with Pinecone")
    print("=" * 60)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ö†Ô∏è  Pinecone API key not configured")
            return
        
        pc = Pinecone(api_key=api_key)
        index = pc.Index("rag-demo-index")
        model = genai.GenerativeModel('gemini-pro')
        
        def rag_with_pinecone(question: str, top_k: int = 3):
            """Complete RAG pipeline with Pinecone"""
            
            print(f"\n{'='*60}")
            print(f"‚ùì Question: {question}")
            print(f"{'='*60}")
            
            # Step 1: Generate query embedding
            print("\n1Ô∏è‚É£ Generating query embedding...")
            query_result = genai.embed_content(
                model="models/embedding-001",
                content=question,
                task_type="retrieval_query"
            )
            query_embedding = query_result['embedding']
            print("   ‚úÖ Embedding generated")
            
            # Step 2: Search Pinecone
            print("\n2Ô∏è‚É£ Searching Pinecone index...")
            results = index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True
            )
            print(f"   ‚úÖ Found {len(results['matches'])} matches")
            
            # Step 3: Extract context
            print("\n3Ô∏è‚É£ Building context from results...")
            contexts = []
            for match in results['matches']:
                text = match['metadata']['text']
                score = match['score']
                contexts.append(f"[Relevance: {score:.2f}] {text}")
            
            context = "\n".join(contexts)
            print(f"   ‚úÖ Context prepared ({len(contexts)} documents)")
            
            # Step 4: Generate response
            print("\n4Ô∏è‚É£ Generating AI response...")
            
            prompt = f"""Based on the following context, answer the question.

Context:
{context}

Question: {question}

Answer: Provide a clear answer based on the context. Cite relevant information."""
            
            response = model.generate_content(prompt)
            print("   ‚úÖ Response generated")
            
            # Display results
            print(f"\n{'='*60}")
            print("üìÑ RETRIEVED CONTEXT:")
            print(f"{'='*60}")
            for i, ctx in enumerate(contexts, 1):
                print(f"\n{i}. {ctx}")
            
            print(f"\n{'='*60}")
            print("ü§ñ AI RESPONSE:")
            print(f"{'='*60}")
            print(response.text)
            print()
            
            return response.text
        
        # Test questions
        test_questions = [
            "What is Python known for?",
            "Which Python frameworks should I use for web development?",
            "What libraries are available for machine learning?"
        ]
        
        for question in test_questions:
            rag_with_pinecone(question)
            time.sleep(1)  # Brief pause between queries
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
    except Exception as e:
        print(f"‚ùå Error in RAG pipeline: {e}")


# ============================================================================
# SECTION 7: Metadata Filtering
# ============================================================================

def metadata_filtering():
    """
    Demonstrate metadata filtering in Pinecone
    """
    print("\n" + "=" * 60)
    print("SECTION 7: Metadata Filtering")
    print("=" * 60)
    
    print("""
    üè∑Ô∏è METADATA FILTERING:
    
    Pinecone allows filtering by metadata BEFORE similarity search.
    This enables:
    ‚Ä¢ Search within specific categories
    ‚Ä¢ Filter by date, author, source
    ‚Ä¢ Permissions-based access
    ‚Ä¢ Multi-tenant applications
    
    Example filters:
    ‚Ä¢ {"category": "data-science"}
    ‚Ä¢ {"date": {"$gte": "2023-01-01"}}
    ‚Ä¢ {"author": "John Doe"}
    """)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("\n‚ö†Ô∏è  Pinecone API key not configured")
            return
        
        pc = Pinecone(api_key=api_key)
        index = pc.Index("rag-demo-index")
        
        query = "Tell me about Python"
        
        # Generate query embedding
        query_result = genai.embed_content(
            model="models/embedding-001",
            content=query,
            task_type="retrieval_query"
        )
        query_embedding = query_result['embedding']
        
        # Test different filters
        filters = [
            (None, "No filter (all categories)"),
            ({"category": "frameworks"}, "Only 'frameworks'"),
            ({"category": "data-science"}, "Only 'data-science'")
        ]
        
        for filter_dict, description in filters:
            print(f"\n{'='*60}")
            print(f"üîç {description}")
            print(f"{'='*60}")
            
            results = index.query(
                vector=query_embedding,
                top_k=3,
                include_metadata=True,
                filter=filter_dict
            )
            
            print(f"\nFound {len(results['matches'])} results:\n")
            
            for i, match in enumerate(results['matches'], 1):
                text = match['metadata']['text']
                category = match['metadata']['category']
                score = match['score']
                
                print(f"{i}. [{category}] (score: {score:.4f})")
                print(f"   {text}\n")
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
    except Exception as e:
        print(f"‚ùå Error: {e}")


# ============================================================================
# SECTION 8: Production Best Practices
# ============================================================================

def production_best_practices():
    """
    Best practices for production RAG with Pinecone
    """
    print("\n" + "=" * 60)
    print("SECTION 8: Production Best Practices")
    print("=" * 60)
    
    practices = """
    ‚úÖ INDEXING STRATEGY:
    
    1. Batch Operations
       ‚Ä¢ Upsert in batches (100-1000 vectors)
       ‚Ä¢ Parallel processing for speed
       ‚Ä¢ Use async operations when possible
    
    2. Metadata Design
       ‚Ä¢ Keep metadata small
       ‚Ä¢ Index frequently filtered fields
       ‚Ä¢ Include source information
       ‚Ä¢ Add timestamps
    
    3. ID Management
       ‚Ä¢ Use meaningful, unique IDs
       ‚Ä¢ Include source in ID (e.g., "doc1_chunk3")
       ‚Ä¢ Enable easy updates/deletes
    
    
    ‚úÖ SEARCH OPTIMIZATION:
    
    1. Top-K Selection
       ‚Ä¢ Start with 3-5
       ‚Ä¢ Increase if needed
       ‚Ä¢ Balance relevance vs cost
    
    2. Reranking
       ‚Ä¢ Retrieve more (e.g., 20)
       ‚Ä¢ Rerank to get best 3-5
       ‚Ä¢ Improves precision
    
    3. Caching
       ‚Ä¢ Cache common queries
       ‚Ä¢ Cache embeddings
       ‚Ä¢ Use CDN for static content
    
    
    ‚úÖ SCALING:
    
    1. Index Organization
       ‚Ä¢ Use namespaces for logical separation
       ‚Ä¢ Separate indexes for different domains
       ‚Ä¢ Consider multi-index architecture
    
    2. Performance Monitoring
       ‚Ä¢ Track query latency
       ‚Ä¢ Monitor index size
       ‚Ä¢ Watch API usage
       ‚Ä¢ Set up alerts
    
    3. Cost Management
       ‚Ä¢ Right-size your plan
       ‚Ä¢ Monitor vector counts
       ‚Ä¢ Delete unused data
       ‚Ä¢ Use serverless efficiently
    
    
    ‚úÖ RELIABILITY:
    
    1. Error Handling
       ‚Ä¢ Retry logic with backoff
       ‚Ä¢ Handle API errors gracefully
       ‚Ä¢ Fallback strategies
       ‚Ä¢ Circuit breakers
    
    2. Testing
       ‚Ä¢ Unit tests for components
       ‚Ä¢ Integration tests
       ‚Ä¢ Load testing
       ‚Ä¢ Relevance evaluation
    
    3. Monitoring
       ‚Ä¢ Query success rate
       ‚Ä¢ Retrieval quality
       ‚Ä¢ Response times
       ‚Ä¢ User satisfaction
    
    
    ‚úÖ SECURITY:
    
    1. Access Control
       ‚Ä¢ Use API keys properly
       ‚Ä¢ Rotate keys regularly
       ‚Ä¢ Implement authentication
       ‚Ä¢ Use namespaces for isolation
    
    2. Data Privacy
       ‚Ä¢ Encrypt sensitive data
       ‚Ä¢ PII handling
       ‚Ä¢ Compliance (GDPR, etc.)
       ‚Ä¢ Data retention policies
    
    3. Rate Limiting
       ‚Ä¢ Implement request limits
       ‚Ä¢ Prevent abuse
       ‚Ä¢ Fair usage policies
    
    
    üí° EXAMPLE PRODUCTION ARCHITECTURE:
    
    User Request
        ‚Üì
    API Gateway (auth, rate limiting)
        ‚Üì
    Application Server
        ‚Üì
    ‚îú‚îÄ‚Üí Cache Layer (Redis)
    ‚îú‚îÄ‚Üí Embedding Service
    ‚îÇ       ‚Üì
    ‚îî‚îÄ‚Üí Pinecone Index
        ‚Üì
    LLM Service (Gemini)
        ‚Üì
    Response
        ‚Üì
    Logging & Monitoring
    
    
    üìä METRICS TO TRACK:
    
    ‚Ä¢ Query latency (p50, p95, p99)
    ‚Ä¢ Retrieval precision @ k
    ‚Ä¢ Answer quality scores
    ‚Ä¢ Cache hit rate
    ‚Ä¢ API costs
    ‚Ä¢ Error rates
    ‚Ä¢ User satisfaction (feedback)
    
    
    üîß MAINTENANCE:
    
    1. Regular Updates
       ‚Ä¢ Add new documents
       ‚Ä¢ Remove outdated content
       ‚Ä¢ Update embeddings if model changes
    
    2. Performance Tuning
       ‚Ä¢ Optimize chunk sizes
       ‚Ä¢ Adjust top-k
       ‚Ä¢ Refine metadata
       ‚Ä¢ A/B test changes
    
    3. Documentation
       ‚Ä¢ Index schema
       ‚Ä¢ Metadata fields
       ‚Ä¢ Query patterns
       ‚Ä¢ Runbooks for issues
    """
    
    print(practices)


# ============================================================================
# SECTION 9: Cleanup
# ============================================================================

def cleanup_demo():
    """
    Clean up demo resources
    """
    print("\n" + "=" * 60)
    print("SECTION 9: Cleanup")
    print("=" * 60)
    
    try:
        from pinecone import Pinecone
        
        api_key = os.getenv('PINECONE_API_KEY')
        
        if not api_key:
            print("‚ö†Ô∏è  Pinecone API key not configured")
            return
        
        pc = Pinecone(api_key=api_key)
        index_name = "rag-demo-index"
        
        choice = input(f"\n‚ö†Ô∏è  Delete index '{index_name}'? (yes/no): ").strip().lower()
        
        if choice == 'yes':
            print("\n‚è≥ Deleting index...")
            pc.delete_index(index_name)
            print("‚úÖ Index deleted successfully!")
            print("\nüí° You can recreate it anytime by running the setup sections")
        else:
            print("\n‚úÖ Index preserved")
            print("\nüí° To manually delete later:")
            print(f"   pc.delete_index('{index_name}')")
        
    except ImportError:
        print("‚ùå Pinecone library not installed")
    except Exception as e:
        print(f"‚ùå Error: {e}")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main function with menu
    """
    print("\n")
    print("üéì " + "=" * 58 + " üéì")
    print("    GENERATIVE AI SESSION - MODULE 10: RAG WITH PINECONE")
    print("üéì " + "=" * 58 + " üéì")
    
    menu = """
    Choose a section to run:
    
    1. Understanding Vector Databases
    2. Pinecone Setup Guide
    3. Create Pinecone Index
    4. Index Documents
    5. Query Pinecone
    6. Complete RAG Pipeline
    7. Metadata Filtering
    8. Production Best Practices
    9. Cleanup (Delete Demo Index)
    
    setup - Run setup (sections 2-4)
    demo - Run demo (sections 5-7)
    all - Run all (except cleanup)
    quit - Exit
    
    """
    
    while True:
        print(menu)
        choice = input("Your choice: ").strip().lower()
        
        if choice in ['quit', 'q', 'exit']:
            print("üëã Goodbye!")
            break
        elif choice == '1':
            vector_database_concepts()
        elif choice == '2':
            pinecone_setup_guide()
        elif choice == '3':
            create_pinecone_index()
        elif choice == '4':
            index_documents()
        elif choice == '5':
            query_pinecone()
        elif choice == '6':
            complete_rag_pinecone()
        elif choice == '7':
            metadata_filtering()
        elif choice == '8':
            production_best_practices()
        elif choice == '9':
            cleanup_demo()
        elif choice == 'setup':
            print("\nüîß Running setup sequence...")
            if pinecone_setup_guide():
                create_pinecone_index()
                index_documents()
            print("\n‚úÖ Setup complete!")
        elif choice == 'demo':
            print("\nüé¨ Running demo sequence...")
            query_pinecone()
            complete_rag_pinecone()
            metadata_filtering()
            print("\n‚úÖ Demo complete!")
        elif choice == 'all':
            vector_database_concepts()
            if pinecone_setup_guide():
                create_pinecone_index()
                index_documents()
                query_pinecone()
                complete_rag_pinecone()
                metadata_filtering()
            production_best_practices()
            print("\n‚úÖ All sections completed!")
            break
        else:
            print("‚ö†Ô∏è  Invalid choice. Please try again.")


if __name__ == "__main__":
    main()
    
    # Teaching Questions:
    # 1. Why use a vector database vs in-memory search?
    # 2. How does metadata filtering improve RAG?
    # 3. What are key considerations for production RAG?
