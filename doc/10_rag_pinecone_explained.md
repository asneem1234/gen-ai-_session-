# 10_rag_pinecone.py - Line by Line Explanation

## ğŸ“Š Visual Overview: Vector Databases & Pinecone RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         VECTOR DATABASE = SCALABLE, PRODUCTION-READY RAG          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

THE SCALING PROBLEM:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Basic RAG (Module 09):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“„ 10 documents    â†’ âœ… Fast         â”‚
â”‚ ğŸ“„ 100 documents   â†’ âœ… OK           â”‚
â”‚ ğŸ“„ 1,000 documents â†’ âš ï¸  Slow        â”‚
â”‚ ğŸ“„ 10,000 documents â†’ âŒ Very Slow   â”‚
â”‚ ğŸ“„ 100,000 documents â†’ âŒ Impossible â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Vector Database RAG (Module 10):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“„ 10 documents      â†’ âœ… Fast       â”‚
â”‚ ğŸ“„ 100 documents     â†’ âœ… Fast       â”‚
â”‚ ğŸ“„ 1,000 documents   â†’ âœ… Fast       â”‚
â”‚ ğŸ“„ 10,000 documents  â†’ âœ… Fast       â”‚
â”‚ ğŸ“„ 1,000,000 docs    â†’ âœ… Fast       â”‚
â”‚ ğŸ“„ 1,000,000,000 docs â†’ âœ… Still Fast!â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ARCHITECTURE COMPARISON:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BASIC RAG (In-Memory):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your Python Script                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ embeddings = []  â† All in RAM       â”‚
â”‚ chunks = []      â† All in RAM       â”‚
â”‚                                     â”‚
â”‚ for each query:                     â”‚
â”‚   for each embedding:  â† O(n) searchâ”‚
â”‚     calculate similarity            â”‚
â”‚   return top matches                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Limitations:
âŒ RAM limited (can't handle millions)
âŒ Linear search (slow with scale)
âŒ No persistence (lost on restart)
âŒ No concurrent access
âŒ No updates without recomputing all


VECTOR DATABASE RAG (Pinecone):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your Python Script                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ API Call
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pinecone Cloud Service              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Vector Index                â”‚   â”‚
â”‚ â”‚ (Optimized data structure)  â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ANN Search Engine           â”‚   â”‚
â”‚ â”‚ (Approximate Nearest        â”‚   â”‚
â”‚ â”‚  Neighbor - super fast!)    â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Distributed Storage         â”‚   â”‚
â”‚ â”‚ (Handles billions of vectors)â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
âœ… Scales to billions of vectors
âœ… Sub-millisecond search
âœ… Persistent storage
âœ… Concurrent access
âœ… Real-time updates
âœ… Production-ready
```

---

## ğŸ—ï¸ Pinecone vs Basic RAG Flow

```
BASIC RAG FLOW (Module 09):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Setup Phase:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Load documents                  â”‚
â”‚ 2. Chunk text                      â”‚
â”‚ 3. Create embeddings               â”‚
â”‚ 4. Store in Python list/array      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    (In RAM only - lost on restart)

Query Phase:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embed query                     â”‚
â”‚ 2. Compare with ALL embeddings     â”‚â† Linear O(n)
â”‚ 3. Sort by similarity              â”‚
â”‚ 4. Return top K                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Takes longer as data grows


PINECONE RAG FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Setup Phase (One-time):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Create Pinecone index           â”‚
â”‚    (Define dimensions, metric)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Empty Index   â”‚
         â”‚ (Cloud-hosted)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Load & chunk documents          â”‚
â”‚ 3. Create embeddings               â”‚
â”‚ 4. Upsert to Pinecone              â”‚
â”‚    (Persistent storage)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Indexed & Optimized â”‚â† Stays forever
    â”‚ (Ready for queries) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query Phase (Every request):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embed query                     â”‚
â”‚ 2. Send to Pinecone API            â”‚
â”‚ 3. Pinecone uses ANN search        â”‚â† Fast O(log n)
â”‚ 4. Returns top K matches           â”‚
â”‚    (with metadata, scores)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Fast regardless of scale!


TIME COMPARISON:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1,000 documents:
Basic RAG:    50ms
Pinecone:     10ms

10,000 documents:
Basic RAG:    500ms  â† Getting slow
Pinecone:     15ms

100,000 documents:
Basic RAG:    5,000ms (5 seconds!) âŒ
Pinecone:     20ms                  âœ…

1,000,000 documents:
Basic RAG:    50,000ms (50 sec!) âŒâŒâŒ
Pinecone:     25ms                âœ…âœ…âœ…
```

---

## ğŸ¯ Vector Database Concepts

```
WHAT IS A VECTOR DATABASE?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Traditional Database:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Table: Users                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ID   â”‚ Name   â”‚ Age  â”‚ City         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1    â”‚ Alice  â”‚ 25   â”‚ NYC          â”‚
â”‚ 2    â”‚ Bob    â”‚ 30   â”‚ LA           â”‚
â”‚ 3    â”‚ Carol  â”‚ 28   â”‚ Chicago      â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Queries: Exact match or range
- Find name = "Alice"
- Find age > 25
- Find city = "NYC"


Vector Database:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Index: Documents                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ID   â”‚ Vector (768 dims)    â”‚ Metadata         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ doc1 â”‚ [0.23, 0.87, ...]   â”‚ {source: "a.txt"}â”‚
â”‚ doc2 â”‚ [0.45, 0.12, ...]   â”‚ {source: "b.txt"}â”‚
â”‚ doc3 â”‚ [0.91, 0.33, ...]   â”‚ {source: "c.txt"}â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Queries: Similarity search
- Find vectors similar to [0.25, 0.85, ...]
- Returns: Closest matches by distance


SEARCH ALGORITHMS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Basic RAG (Brute Force):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Vector: [0.5, 0.8, 0.3]       â”‚
â”‚          â†“                           â”‚
â”‚ Compare with EVERY vector:           â”‚
â”‚   â€¢ Vector 1: [0.6, 0.7, 0.4]       â”‚
â”‚   â€¢ Vector 2: [0.1, 0.2, 0.9]       â”‚
â”‚   â€¢ Vector 3: [0.5, 0.8, 0.2]       â”‚
â”‚   â€¢ ... (continue for ALL)           â”‚
â”‚          â†“                           â”‚
â”‚ Complexity: O(n)                     â”‚
â”‚ Time: Linear with dataset size       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Vector DB (ANN - Approximate Nearest Neighbor):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Vector: [0.5, 0.8, 0.3]       â”‚
â”‚          â†“                           â”‚
â”‚ Use optimized index structure:       â”‚
â”‚   â€¢ HNSW (graph-based)              â”‚
â”‚   â€¢ IVF (clustering-based)          â”‚
â”‚   â€¢ LSH (hashing-based)             â”‚
â”‚          â†“                           â”‚
â”‚ Check only relevant regions          â”‚
â”‚ (Not all vectors!)                   â”‚
â”‚          â†“                           â”‚
â”‚ Complexity: O(log n)                 â”‚
â”‚ Time: Logarithmic - stays fast!      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VISUAL: ANN SEARCH STRATEGY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Imagine vector space divided into regions:

    Region A    Region B    Region C
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢   â€¢    â”‚    â€¢     â”‚     â€¢    â”‚
â”‚  â€¢    â€¢  â”‚  â€¢   â€¢   â”‚  â€¢     â€¢ â”‚
â”‚   â€¢  â€¢   â”‚ â€¢     â€¢  â”‚    â€¢   â€¢ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query: â­ falls in Region B
       â†“
Only search Region B (+ neighbors)
Skip Regions A and C completely!
       â†“
Result: 100x faster than checking all!
```

---

## ğŸŒ² Pinecone Architecture

```
PINECONE SYSTEM OVERVIEW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              YOUR APPLICATION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  import pinecone                               â”‚
â”‚  pc = Pinecone(api_key="...")                 â”‚
â”‚  index = pc.Index("my-index")                  â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTPS API
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PINECONE CLOUD SERVICE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  API Layer                           â”‚     â”‚
â”‚  â”‚  - Authentication                     â”‚     â”‚
â”‚  â”‚  - Rate limiting                      â”‚     â”‚
â”‚  â”‚  - Request routing                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â”‚                                 â”‚
â”‚               â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Index Management                     â”‚     â”‚
â”‚  â”‚  - Multiple indexes                   â”‚     â”‚
â”‚  â”‚  - Namespaces                         â”‚     â”‚
â”‚  â”‚  - Metadata filtering                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â”‚                                 â”‚
â”‚               â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Vector Search Engine                 â”‚     â”‚
â”‚  â”‚  - HNSW algorithm                     â”‚     â”‚
â”‚  â”‚  - Approximate search                 â”‚     â”‚
â”‚  â”‚  - Sub-millisecond queries            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚               â”‚                                 â”‚
â”‚               â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Distributed Storage                  â”‚     â”‚
â”‚  â”‚  - Scalable                           â”‚     â”‚
â”‚  â”‚  - Replicated                         â”‚     â”‚
â”‚  â”‚  - Persistent                         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


PINECONE INDEX STRUCTURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Index: "my-rag-index"
â”œâ”€â”€ Namespace: "default"
â”‚   â”œâ”€â”€ Vector: doc-1
â”‚   â”‚   â”œâ”€â”€ ID: "doc-1"
â”‚   â”‚   â”œâ”€â”€ Values: [0.23, 0.87, ...] (768 dims)
â”‚   â”‚   â””â”€â”€ Metadata: {"source": "file1.txt", "page": 1}
â”‚   â”‚
â”‚   â”œâ”€â”€ Vector: doc-2
â”‚   â”‚   â”œâ”€â”€ ID: "doc-2"
â”‚   â”‚   â”œâ”€â”€ Values: [0.45, 0.12, ...]
â”‚   â”‚   â””â”€â”€ Metadata: {"source": "file2.txt", "page": 1}
â”‚   â”‚
â”‚   â””â”€â”€ Vector: doc-3
â”‚       â”œâ”€â”€ ID: "doc-3"
â”‚       â”œâ”€â”€ Values: [0.91, 0.33, ...]
â”‚       â””â”€â”€ Metadata: {"source": "file3.txt", "page": 2}
â”‚
â””â”€â”€ Namespace: "archive"
    â””â”€â”€ (Old documents)


PINECONE OPERATIONS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. CREATE INDEX:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pc.create_index(                   â”‚
â”‚     name="my-index",               â”‚
â”‚     dimension=768,                 â”‚
â”‚     metric="cosine"                â”‚
â”‚ )                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Creates empty index


2. UPSERT VECTORS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index.upsert(vectors=[             â”‚
â”‚     {                              â”‚
â”‚         "id": "doc-1",             â”‚
â”‚         "values": [0.23, 0.87,...],â”‚
â”‚         "metadata": {"src": "a"}   â”‚
â”‚     }                              â”‚
â”‚ ])                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Stores in Pinecone


3. QUERY:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(             â”‚
â”‚     vector=[0.25, 0.88, ...],     â”‚
â”‚     top_k=5,                       â”‚
â”‚     include_metadata=True          â”‚
â”‚ )                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Returns top 5 matches


4. UPDATE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index.update(                      â”‚
â”‚     id="doc-1",                    â”‚
â”‚     metadata={"updated": True}     â”‚
â”‚ )                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Modifies existing vector


5. DELETE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index.delete(ids=["doc-1"])       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Removes vector
```

---

## ğŸ“¦ Code Structure Map

```
10_rag_pinecone.py
â”‚
â”œâ”€â”€ ğŸ“¦ IMPORTS
â”‚   â”œâ”€â”€ os, dotenv
â”‚   â”œâ”€â”€ google.generativeai
â”‚   â”œâ”€â”€ pinecone (vector database)
â”‚   â””â”€â”€ typing, time
â”‚
â”œâ”€â”€ ğŸ”§ SETUP
â”‚   â”œâ”€â”€ load_dotenv()
â”‚   â”œâ”€â”€ genai.configure()
â”‚   â””â”€â”€ Initialize Pinecone client
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 1: vector_database_concepts()
â”‚   â””â”€â”€ Educational overview of vector DBs
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 2: setup_pinecone()
â”‚   â”œâ”€â”€ Initialize Pinecone client
â”‚   â”œâ”€â”€ Create index (if needed)
â”‚   â””â”€â”€ Return index object
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 3: create_embeddings()
â”‚   â”œâ”€â”€ Input: text or list of texts
â”‚   â”œâ”€â”€ Use Google embedding model
â”‚   â””â”€â”€ Return: embedding vectors
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 4: index_documents()
â”‚   â”œâ”€â”€ Load documents
â”‚   â”œâ”€â”€ Chunk text
â”‚   â”œâ”€â”€ Create embeddings
â”‚   â”œâ”€â”€ Prepare vectors with metadata
â”‚   â””â”€â”€ Upsert to Pinecone
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 5: query_pinecone()
â”‚   â”œâ”€â”€ Embed user query
â”‚   â”œâ”€â”€ Search Pinecone index
â”‚   â”œâ”€â”€ Return matches with scores
â”‚   â””â”€â”€ Include metadata
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 6: rag_with_pinecone()
â”‚   â”œâ”€â”€ Query Pinecone for context
â”‚   â”œâ”€â”€ Build RAG prompt
â”‚   â”œâ”€â”€ Generate AI response
â”‚   â””â”€â”€ Return answer + sources
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 7: metadata_filtering()
â”‚   â”œâ”€â”€ Filter by document source
â”‚   â”œâ”€â”€ Filter by date
â”‚   â”œâ”€â”€ Filter by category
â”‚   â””â”€â”€ Demonstrate filtered search
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 8: update_and_delete()
â”‚   â”œâ”€â”€ Update vector metadata
â”‚   â”œâ”€â”€ Delete specific vectors
â”‚   â””â”€â”€ Demonstrate CRUD operations
â”‚
â”œâ”€â”€ ğŸ¯ SECTION 9: production_patterns()
â”‚   â”œâ”€â”€ Batch upserts
â”‚   â”œâ”€â”€ Error handling
â”‚   â”œâ”€â”€ Retry logic
â”‚   â””â”€â”€ Monitoring & logging
â”‚
â””â”€â”€ ğŸš€ MAIN DEMO
    â”œâ”€â”€ Setup Pinecone
    â”œâ”€â”€ Index sample documents
    â”œâ”€â”€ Run queries
    â”œâ”€â”€ Demonstrate filtering
    â””â”€â”€ Show updates/deletes
```

---

## ğŸ”„ Complete RAG Pipeline with Pinecone

```
PRODUCTION RAG WORKFLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 1: ONE-TIME SETUP
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Step 1: Create Pinecone Account
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Sign up at pinecone.io       â”‚
â”‚ â€¢ Get API key                  â”‚
â”‚ â€¢ Choose region                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Create Index
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ from pinecone import Pinecone  â”‚
â”‚                                â”‚
â”‚ pc = Pinecone(api_key="...")  â”‚
â”‚                                â”‚
â”‚ pc.create_index(               â”‚
â”‚     name="rag-index",          â”‚
â”‚     dimension=768,             â”‚
â”‚     metric="cosine",           â”‚
â”‚     spec=ServerlessSpec(       â”‚
â”‚         cloud="aws",           â”‚
â”‚         region="us-east-1"     â”‚
â”‚     )                          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Index created in cloud


PHASE 2: INDEXING DOCUMENTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Step 3: Prepare Documents
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ documents = [                  â”‚
â”‚     "Python is a language...", â”‚
â”‚     "Machine learning uses...",â”‚
â”‚     "Data science requires..." â”‚
â”‚ ]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Chunk & Embed
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ chunks = []                    â”‚
â”‚ for doc in documents:          â”‚
â”‚     chunks.extend(             â”‚
â”‚         chunk_text(doc)        â”‚
â”‚     )                          â”‚
â”‚                                â”‚
â”‚ embeddings = []                â”‚
â”‚ for chunk in chunks:           â”‚
â”‚     emb = create_embedding(    â”‚
â”‚         chunk                  â”‚
â”‚     )                          â”‚
â”‚     embeddings.append(emb)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 5: Prepare Vectors
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ vectors = []                   â”‚
â”‚ for i, (chunk, emb) in         â”‚
â”‚     enumerate(                 â”‚
â”‚         zip(chunks, embeddings)â”‚
â”‚     ):                         â”‚
â”‚     vectors.append({           â”‚
â”‚         "id": f"doc-{i}",      â”‚
â”‚         "values": emb,         â”‚
â”‚         "metadata": {          â”‚
â”‚             "text": chunk,     â”‚
â”‚             "source": "file1"  â”‚
â”‚         }                      â”‚
â”‚     })                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 6: Upsert to Pinecone
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index = pc.Index("rag-index")  â”‚
â”‚                                â”‚
â”‚ index.upsert(                  â”‚
â”‚     vectors=vectors,           â”‚
â”‚     namespace="default"        â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    âœ… Documents indexed!


PHASE 3: QUERYING (PRODUCTION)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Step 7: User Asks Question
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: "How do I use Python     â”‚
â”‚        for machine learning?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 8: Embed Query
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ query = "How to use Python..." â”‚
â”‚                                â”‚
â”‚ query_emb = create_embedding(  â”‚
â”‚     query                      â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 9: Search Pinecone
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=3,                   â”‚
â”‚     include_metadata=True      â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Returns: [
        {id: "doc-5", score: 0.92, metadata: {...}},
        {id: "doc-2", score: 0.87, metadata: {...}},
        {id: "doc-8", score: 0.81, metadata: {...}}
    ]

Step 10: Extract Context
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ context = ""                   â”‚
â”‚ for match in results.matches:  â”‚
â”‚     context += match.metadata  â”‚
â”‚                   ["text"]     â”‚
â”‚     context += "\n\n"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 11: Build RAG Prompt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prompt = f"""                  â”‚
â”‚ Context:                       â”‚
â”‚ {context}                      â”‚
â”‚                                â”‚
â”‚ Question: {query}              â”‚
â”‚                                â”‚
â”‚ Answer based on context:       â”‚
â”‚ """                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 12: Generate Answer
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ model = genai.GenerativeModel( â”‚
â”‚     'gemini-2.0-flash'        â”‚
â”‚ )                              â”‚
â”‚                                â”‚
â”‚ response = model.generate(     â”‚
â”‚     prompt                     â”‚
â”‚ )                              â”‚
â”‚                                â”‚
â”‚ return response.text           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    ğŸ“ "To use Python for machine
       learning, you can use
       libraries like scikit-learn
       and TensorFlow..."


COMPLETE FLOW DIAGRAM:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

User Question
     â†“
Embed Query â†’ [0.25, 0.88, ...]
     â†“
API Call to Pinecone
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pinecone Search    â”‚
â”‚  (milliseconds!)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
Return Top Matches
     â†“
Extract Text from Metadata
     â†“
Build Prompt with Context
     â†“
Send to AI Model (Gemini)
     â†“
Generate Answer
     â†“
Return to User
```

---

## ğŸ” Metadata Filtering Examples

```
WHY METADATA?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Without Metadata:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query: "2024 sales data"         â”‚
â”‚    â†“                             â”‚
â”‚ Returns: ALL sales documents    â”‚
â”‚ (2020, 2021, 2022, 2023, 2024)  â”‚
â”‚    â†“                             â”‚
â”‚ Must filter results manually âŒ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Metadata:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query: "2024 sales data"         â”‚
â”‚ Filter: {"year": 2024}          â”‚
â”‚    â†“                             â”‚
â”‚ Returns: Only 2024 documents âœ…  â”‚
â”‚    â†“                             â”‚
â”‚ More relevant, faster           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


METADATA STRUCTURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Vector with Rich Metadata:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                       â”‚
â”‚   "id": "doc-123",                      â”‚
â”‚   "values": [0.23, 0.87, ...],         â”‚
â”‚   "metadata": {                         â”‚
â”‚     "text": "Q4 sales were $5M...",   â”‚
â”‚     "source": "q4_report.pdf",         â”‚
â”‚     "year": 2024,                       â”‚
â”‚     "quarter": "Q4",                    â”‚
â”‚     "department": "sales",              â”‚
â”‚     "category": "financial",            â”‚
â”‚     "author": "john@company.com",       â”‚
â”‚     "date": "2024-12-01"               â”‚
â”‚   }                                     â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


FILTERING EXAMPLES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Filter by Year:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=5,                   â”‚
â”‚     filter={"year": 2024}      â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returns only 2024 documents


2. Filter by Department:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=5,                   â”‚
â”‚     filter={                   â”‚
â”‚         "department": "sales"  â”‚
â”‚     }                          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returns only sales documents


3. Multiple Filters (AND):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=5,                   â”‚
â”‚     filter={                   â”‚
â”‚         "year": 2024,          â”‚
â”‚         "department": "sales", â”‚
â”‚         "quarter": "Q4"        â”‚
â”‚     }                          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returns: 2024 Q4 sales documents


4. OR Filters:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=5,                   â”‚
â”‚     filter={                   â”‚
â”‚         "$or": [               â”‚
â”‚             {"year": 2023},    â”‚
â”‚             {"year": 2024}     â”‚
â”‚         ]                      â”‚
â”‚     }                          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returns: 2023 OR 2024 documents


5. Range Filters:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results = index.query(         â”‚
â”‚     vector=query_emb,          â”‚
â”‚     top_k=5,                   â”‚
â”‚     filter={                   â”‚
â”‚         "year": {              â”‚
â”‚             "$gte": 2022,      â”‚
â”‚             "$lte": 2024       â”‚
â”‚         }                      â”‚
â”‚     }                          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Returns: 2022-2024 documents


METADATA BEST PRACTICES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… DO:
â€¢ Include source/origin
â€¢ Add timestamps
â€¢ Tag with categories
â€¢ Include author/creator
â€¢ Add hierarchical tags
â€¢ Keep metadata concise

âŒ DON'T:
â€¢ Store large text in metadata
â€¢ Use inconsistent formats
â€¢ Over-index (too many fields)
â€¢ Forget to update metadata
```

---

## âš¡ Performance & Scaling

```
PERFORMANCE METRICS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Basic RAG vs Pinecone:

Dataset: 10,000 documents
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation      â”‚ Basic    â”‚ Pinecone â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Indexing       â”‚ 1 min    â”‚ 2 min    â”‚
â”‚ Query (1st)    â”‚ 500ms    â”‚ 15ms     â”‚
â”‚ Query (10th)   â”‚ 500ms    â”‚ 10ms     â”‚
â”‚ Update         â”‚ Re-index â”‚ Instant  â”‚
â”‚ Memory         â”‚ 2GB RAM  â”‚ 50MB RAM â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dataset: 100,000 documents
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation      â”‚ Basic    â”‚ Pinecone â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Indexing       â”‚ 10 min   â”‚ 20 min   â”‚
â”‚ Query          â”‚ 5 sec âŒ â”‚ 20ms âœ…  â”‚
â”‚ Memory         â”‚ 20GB âŒ  â”‚ 50MB âœ…  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dataset: 1,000,000 documents
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation      â”‚ Basic    â”‚ Pinecone â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Indexing       â”‚ Impossibleâ”‚ 3 hours â”‚
â”‚ Query          â”‚ Impossibleâ”‚ 30ms    â”‚
â”‚ Memory         â”‚ 200GB âŒâŒâ”‚ 50MB âœ…âœ…â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


SCALING STRATEGIES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Batch Upserts:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BAD (one at a time):           â”‚
â”‚ for vector in vectors:         â”‚
â”‚     index.upsert([vector])  âŒ â”‚
â”‚ Time: 100 vectors = 10 sec     â”‚
â”‚                                â”‚
â”‚ GOOD (batch):                  â”‚
â”‚ index.upsert(                  â”‚
â”‚     vectors=vectors,           â”‚
â”‚     batch_size=100          âœ… â”‚
â”‚ )                              â”‚
â”‚ Time: 100 vectors = 1 sec      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Parallel Processing:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ import concurrent.futures      â”‚
â”‚                                â”‚
â”‚ def process_batch(batch):      â”‚
â”‚     embeddings = create_emb()  â”‚
â”‚     index.upsert(embeddings)   â”‚
â”‚                                â”‚
â”‚ with ThreadPoolExecutor() as e:â”‚
â”‚     e.map(process_batch,       â”‚
â”‚           batches)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. Use Namespaces:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index.upsert(                  â”‚
â”‚     vectors=sales_vectors,     â”‚
â”‚     namespace="sales"          â”‚
â”‚ )                              â”‚
â”‚                                â”‚
â”‚ index.upsert(                  â”‚
â”‚     vectors=eng_vectors,       â”‚
â”‚     namespace="engineering"    â”‚
â”‚ )                              â”‚
â”‚                                â”‚
â”‚ # Query specific namespace     â”‚
â”‚ index.query(                   â”‚
â”‚     ...,                       â”‚
â”‚     namespace="sales"          â”‚
â”‚ )                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


COST OPTIMIZATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Pinecone Pricing Tiers:

Free Tier:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ 1 index                      â”‚
â”‚ â€¢ 100K vectors                 â”‚
â”‚ â€¢ Great for learning/testing   â”‚
â”‚ â€¢ No credit card required      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Starter ($70/month):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Multiple indexes             â”‚
â”‚ â€¢ 5M vectors                   â”‚
â”‚ â€¢ Good for small production    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Enterprise (Custom):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Unlimited indexes            â”‚
â”‚ â€¢ Billions of vectors          â”‚
â”‚ â€¢ Enterprise support           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ† When to Use What

```
DECISION MATRIX:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Use Basic RAG (Module 09) when:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… < 1,000 documents            â”‚
â”‚ âœ… Prototyping/learning         â”‚
â”‚ âœ… Single-user application      â”‚
â”‚ âœ… No persistence needed        â”‚
â”‚ âœ… Simple requirements          â”‚
â”‚ âœ… Budget: $0                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Use Vector DB (Pinecone) when:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… > 1,000 documents            â”‚
â”‚ âœ… Production application       â”‚
â”‚ âœ… Multiple users               â”‚
â”‚ âœ… Need persistence             â”‚
â”‚ âœ… Require fast queries         â”‚
â”‚ âœ… Need updates/deletes         â”‚
â”‚ âœ… Want metadata filtering      â”‚
â”‚ âœ… Scaling expected             â”‚
â”‚ âœ… Budget: $70+/month           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


MIGRATION PATH:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Start:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Basic RAG     â”‚â† Learn concepts
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Scale grows to 1K+ docs
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Add Pinecone  â”‚â† Production-ready
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Need advanced features
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enterprise setup  â”‚â† Full features
â”‚ - Multiple indexesâ”‚
â”‚ - Advanced filtersâ”‚
â”‚ - Monitoring      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ARCHITECTURE RECOMMENDATIONS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Small Project:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Script            â”‚
â”‚    â†“                     â”‚
â”‚ Basic RAG (in-memory)    â”‚
â”‚    â†“                     â”‚
â”‚ Local files              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Medium Project:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flask/FastAPI            â”‚
â”‚    â†“                     â”‚
â”‚ Pinecone (free tier)     â”‚
â”‚    â†“                     â”‚
â”‚ Cloud storage            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Large Production:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancer            â”‚
â”‚    â†“                     â”‚
â”‚ API Servers (multiple)   â”‚
â”‚    â†“                     â”‚
â”‚ Pinecone (paid tier)     â”‚
â”‚    â†“                     â”‚
â”‚ S3/Cloud storage         â”‚
â”‚    â†“                     â”‚
â”‚ Monitoring/Logging       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Code with Detailed Comments

```python
"""
10 - RAG with Pinecone Vector Database
========================================

This module demonstrates building production-ready RAG with Pinecone.
Students will learn:
- What vector databases are
- Setting up Pinecone
- Indexing documents at scale
- Efficient similarity search
- Production RAG patterns
- Metadata filtering
- Scaling considerations

Teaching Points:
- Vector databases enable efficient large-scale RAG
- Pinecone handles indexing and search infrastructure
- Essential for production applications
- Much more scalable than basic implementations
"""
# Module docstring: Describes the purpose and learning objectives of this module
# This is a comprehensive guide to using Pinecone vector database for RAG applications

import os
# Imports the os module for operating system operations (reading environment variables)

from dotenv import load_dotenv
# Imports load_dotenv to load environment variables from a .env file

import google.generativeai as genai
# Imports Google's Generative AI library and gives it an alias 'genai' for easier use

from typing import List, Dict
# Imports type hints for better code documentation: List and Dict types

import time
# Imports time module for adding delays and pauses in execution


# Setup
load_dotenv()
# Loads environment variables from .env file (API keys, configuration)

genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
# Configures the Google Generative AI library with API key from environment variables


# ============================================================================
# SECTION 1: Understanding Vector Databases
# ============================================================================
# Comment block to separate major sections of code

def vector_database_concepts():
# Defines a function to explain vector database concepts (no parameters needed)

    """
    Explain vector databases and why they're needed
    """
    # Function docstring: Brief description of function purpose
    
    print("\n" + "=" * 60)
    # Prints a newline followed by 60 equal signs for visual separation
    
    print("SECTION 1: Understanding Vector Databases")
    # Prints the section header
    
    print("=" * 60)
    # Prints another line of 60 equal signs to complete the header box
    
    explanation = """
    ğŸ—„ï¸ WHAT ARE VECTOR DATABASES?
    
    Traditional Database:
    â€¢ Stores structured data (rows, columns)
    â€¢ Searches by exact match or ranges
    â€¢ Example: Find users where age > 25
    
    Vector Database:
    â€¢ Stores high-dimensional vectors (embeddings)
    â€¢ Searches by similarity
    â€¢ Example: Find documents similar to query vector
    
    
    âŒ BASIC RAG LIMITATIONS:
    
    1. Scale Issues
       â€¢ Slow with 1000+ documents
       â€¢ All embeddings in memory
       â€¢ Linear search O(n)
    
    2. No Persistence
       â€¢ Recompute embeddings each run
       â€¢ No efficient updates
       â€¢ Can't handle millions of docs
    
    3. No Advanced Features
       â€¢ No metadata filtering
       â€¢ No hybrid search
       â€¢ No distributed architecture
    
    
    âœ… VECTOR DATABASE BENEFITS:
    
    1. Performance
       â€¢ Approximate Nearest Neighbor (ANN) search
       â€¢ Sub-millisecond queries
       â€¢ Scales to billions of vectors
    
    2. Persistence
       â€¢ Durable storage
       â€¢ Easy updates/deletes
       â€¢ Version control
    
    3. Advanced Features
       â€¢ Metadata filtering
       â€¢ Namespaces for organization
       â€¢ Real-time updates
       â€¢ Distributed architecture
    
    4. Production Ready
       â€¢ High availability
       â€¢ Monitoring & analytics
       â€¢ Security features
       â€¢ API access
    
    
    ğŸ† POPULAR VECTOR DATABASES:
    
    1. Pinecone ğŸŒ²
       â€¢ Fully managed (cloud)
       â€¢ Easy to use
       â€¢ Great performance
       â€¢ Free tier available
    
    2. Weaviate
       â€¢ Open source
       â€¢ Rich features
       â€¢ Self-hosted or cloud
    
    3. Qdrant
       â€¢ Rust-based
       â€¢ Fast
       â€¢ Open source
    
    4. Milvus
       â€¢ Open source
       â€¢ Enterprise features
       â€¢ Large scale
    
    5. Chroma
       â€¢ Embedded database
       â€¢ Great for development
       â€¢ Python-first
    
    
    ğŸ¯ WHEN TO USE VECTOR DATABASES:
    
    Use Vector DB when:
    â€¢ 1000+ documents
    â€¢ Production application
    â€¢ Need fast queries
    â€¢ Frequent updates
    â€¢ Multiple users
    
    Basic RAG sufficient for:
    â€¢ Small document sets
    â€¢ Prototyping
    â€¢ Learning
    â€¢ Single-user apps
    
    
    ğŸ“Š PINECONE ARCHITECTURE:
    
    Your App â†’ Pinecone API â†’ Pinecone Index
                                  â†“
                              Vector Storage
                                  â†“
                            ANN Search Engine
                                  â†“
                            Returns Results
    
    Pinecone handles:
    â€¢ Storage
    â€¢ Indexing
    â€¢ Search optimization
    â€¢ Scaling
    â€¢ High availability
    """
    # Multi-line string containing comprehensive educational content about vector databases
    # Explains differences, benefits, popular options, use cases, and architecture
    
    print(explanation)
    # Prints the entire explanation string to the console


# ============================================================================
# SECTION 2: Pinecone Setup
# ============================================================================

def pinecone_setup_guide():
# Defines function to provide setup instructions for Pinecone

    """
    Guide for setting up Pinecone
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    # Prints separator line with newline
    
    print("SECTION 2: Pinecone Setup Guide")
    # Prints section title
    
    print("=" * 60)
    # Prints bottom separator line
    
    guide = """
    ğŸ“ SETUP STEPS:
    
    1. CREATE ACCOUNT
    ==================
    â€¢ Visit: https://www.pinecone.io/
    â€¢ Sign up for free tier
    â€¢ No credit card required for starter
    
    Free Tier Includes:
    â€¢ 1 index
    â€¢ 100K vectors (768 dims)
    â€¢ Good for learning & prototyping
    
    
    2. GET API KEY
    ==============
    â€¢ Dashboard â†’ API Keys
    â€¢ Copy your API key
    â€¢ Copy your environment (e.g., "us-east-1-aws")
    
    
    3. INSTALL LIBRARY
    ==================
    pip install pinecone-client
    
    
    4. CONFIGURE ENVIRONMENT
    ========================
    Add to .env file:
    
    PINECONE_API_KEY=your_api_key_here
    PINECONE_ENVIRONMENT=your_environment_here
    
    
    5. VERIFY SETUP
    ===============
    Run the connection test in this module!
    
    
    ğŸ’» BASIC CODE STRUCTURE:
    
    from pinecone import Pinecone, ServerlessSpec
    
    # Initialize
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    
    # Create index
    pc.create_index(
        name="my-index",
        dimension=768,  # Match your embedding size
        metric="cosine",
        spec=ServerlessSpec(
            cloud="aws",
            region="us-east-1"
        )
    )
    
    # Connect to index
    index = pc.Index("my-index")
    
    # Upsert vectors
    index.upsert(vectors=[
        ("id1", [0.1, 0.2, ...], {"text": "content"})
    ])
    
    # Query
    results = index.query(
        vector=[0.1, 0.2, ...],
        top_k=5,
        include_metadata=True
    )
    
    
    âš™ï¸ KEY CONCEPTS:
    
    â€¢ Index: Container for vectors
    â€¢ Dimension: Size of your embeddings
    â€¢ Metric: cosine, euclidean, or dotproduct
    â€¢ Namespace: Logical partition within index
    â€¢ Metadata: Additional info stored with vectors
    """
    # Multi-line string with step-by-step setup instructions and code examples
    
    print(guide)
    # Displays the setup guide
    
    # Test connection
    print("\n\nğŸ”Œ CONNECTION TEST:")
    # Prints header for connection test section
    
    print("-" * 60)
    # Prints separator line using dashes
    
    try:
    # Starts a try block to handle potential errors gracefully
    
        from pinecone import Pinecone
        # Attempts to import the Pinecone class (will fail if library not installed)
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Retrieves the Pinecone API key from environment variables
        
        if not api_key:
        # Checks if the API key is missing or empty
        
            print("âŒ PINECONE_API_KEY not found in .env file")
            # Informs user that API key is not configured
            
            print("\nğŸ’¡ To use this module:")
            print("   1. Sign up at pinecone.io")
            print("   2. Get your API key")
            print("   3. Add to .env file")
            # Provides helpful instructions for setting up the API key
            
            return False
            # Returns False to indicate connection test failed
        
        # Initialize
        pc = Pinecone(api_key=api_key)
        # Creates a Pinecone client instance using the API key
        
        # List indexes
        indexes = pc.list_indexes()
        # Retrieves list of all existing indexes in the Pinecone account
        
        print("âœ… Connected successfully!")
        # Confirms successful connection
        
        print(f"ğŸ“Š Existing indexes: {len(indexes.indexes)}")
        # Shows how many indexes exist (using f-string for string interpolation)
        
        for idx in indexes.indexes:
        # Loops through each index in the list
        
            print(f"   â€¢ {idx.name}")
            # Prints the name of each index with a bullet point
        
        return True
        # Returns True to indicate successful connection
        
    except ImportError:
    # Catches errors when Pinecone library is not installed
    
        print("âŒ Pinecone library not installed")
        print("   Run: pip install pinecone-client")
        # Provides installation instructions
        
        return False
        # Returns False to indicate failure
        
    except Exception as e:
    # Catches any other unexpected errors
    
        print(f"âŒ Connection error: {e}")
        # Displays the error message
        
        return False
        # Returns False to indicate failure


# ============================================================================
# SECTION 3: Creating a Pinecone Index
# ============================================================================

def create_pinecone_index():
# Defines function to create a new Pinecone index

    """
    Create and configure a Pinecone index
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 3: Creating a Pinecone Index")
    print("=" * 60)
    # Prints section header with decorative lines
    
    try:
    # Starts error handling block
    
        from pinecone import Pinecone, ServerlessSpec
        # Imports Pinecone client and ServerlessSpec for index configuration
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets API key from environment variables
        
        if not api_key:
        # Checks if API key is missing
        
            print("âš ï¸  Pinecone API key not configured")
            print("   This section requires a Pinecone account")
            # Displays warning message
            
            return
            # Exits the function early if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client instance
        
        index_name = "rag-demo-index"
        # Sets the name for the index we'll create
        
        print(f"\nğŸ“ Creating index: {index_name}")
        print("-" * 60)
        # Displays what index is being created
        
        # Check if index already exists
        existing_indexes = [idx.name for idx in pc.list_indexes().indexes]
        # Creates a list of existing index names using list comprehension
        
        if index_name in existing_indexes:
        # Checks if our desired index name already exists
        
            print(f"â„¹ï¸  Index '{index_name}' already exists")
            print("   Deleting and recreating...")
            # Informs user that index will be recreated
            
            pc.delete_index(index_name)
            # Deletes the existing index
            
            time.sleep(1)  # Wait for deletion
            # Pauses for 1 second to ensure deletion completes
        
        # Create index
        print("\nâ³ Creating index...")
        print(f"   â€¢ Name: {index_name}")
        print(f"   â€¢ Dimension: 768 (Gemini embedding size)")
        print(f"   â€¢ Metric: cosine")
        print(f"   â€¢ Cloud: AWS")
        # Shows the configuration details to the user
        
        pc.create_index(
        # Calls the create_index method with configuration parameters
        
            name=index_name,
            # Sets the index name
            
            dimension=768,  # Gemini embedding dimension
            # Sets dimension to 768 (matches Gemini's embedding size)
            
            metric="cosine",
            # Uses cosine similarity for comparing vectors (best for text embeddings)
            
            spec=ServerlessSpec(
            # Specifies serverless configuration (auto-scaling)
            
                cloud="aws",
                # Deploys on AWS infrastructure
                
                region="us-east-1"
                # Uses US East 1 region
            )
        )
        # Completes the index creation
        
        print("\nâœ… Index created successfully!")
        print("\nğŸ’¡ Index configuration:")
        print("   â€¢ Serverless: Scales automatically")
        print("   â€¢ Cosine similarity: Best for text embeddings")
        print("   â€¢ Ready to use immediately")
        # Confirms creation and explains the configuration
        
        # Wait for index to be ready
        print("\nâ³ Waiting for index to be ready...")
        time.sleep(5)
        # Pauses for 5 seconds to allow index initialization
        
        # Get index stats
        index = pc.Index(index_name)
        # Connects to the newly created index
        
        stats = index.describe_index_stats()
        # Retrieves statistics about the index
        
        print("\nğŸ“Š Index Stats:")
        print(f"   â€¢ Total vectors: {stats['total_vector_count']}")
        print(f"   â€¢ Dimension: {stats['dimension']}")
        # Displays index statistics (should show 0 vectors initially)
        
        return index_name
        # Returns the index name for potential use by calling code
        
    except ImportError:
    # Handles case where Pinecone library isn't installed
    
        print("âŒ Pinecone library not installed")
        print("   Run: pip install pinecone-client")
        # Provides installation instructions
        
    except Exception as e:
    # Catches any other errors
    
        print(f"âŒ Error creating index: {e}")
        # Displays the error message


# ============================================================================
# SECTION 4: Indexing Documents
# ============================================================================

def index_documents():
# Defines function to add documents to the Pinecone index

    """
    Index documents into Pinecone
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 4: Indexing Documents")
    print("=" * 60)
    # Prints section header
    
    try:
    # Starts error handling
    
        from pinecone import Pinecone
        # Imports Pinecone client
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets API key from environment
        
        if not api_key:
        # Checks if API key exists
        
            print("âš ï¸  Pinecone API key not configured")
            return
            # Exits if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client
        
        index_name = "rag-demo-index"
        # Sets the index name to use
        
        # Check if index exists
        existing_indexes = [idx.name for idx in pc.list_indexes().indexes]
        # Gets list of existing index names
        
        if index_name not in existing_indexes:
        # Checks if our index doesn't exist
        
            print(f"âš ï¸  Index '{index_name}' not found")
            print("   Run Section 3 to create it first")
            # Tells user to create index first
            
            return
            # Exits function
        
        index = pc.Index(index_name)
        # Connects to the existing index
        
        # Sample documents
        documents = [
        # Creates a list of sample documents to index
        
            {"id": "doc1", "text": "Python is a high-level programming language created by Guido van Rossum.", "category": "intro"},
            # Document 1: Python introduction with unique ID, text content, and category metadata
            
            {"id": "doc2", "text": "Python emphasizes code readability with significant indentation.", "category": "syntax"},
            # Document 2: About Python syntax
            
            {"id": "doc3", "text": "Django is a popular web framework for Python.", "category": "frameworks"},
            # Document 3: About Django framework
            
            {"id": "doc4", "text": "Flask is a lightweight web framework for Python.", "category": "frameworks"},
            # Document 4: About Flask framework
            
            {"id": "doc5", "text": "NumPy provides support for large multi-dimensional arrays.", "category": "data-science"},
            # Document 5: About NumPy library
            
            {"id": "doc6", "text": "Pandas is used for data manipulation and analysis.", "category": "data-science"},
            # Document 6: About Pandas library
            
            {"id": "doc7", "text": "Scikit-learn is a machine learning library for Python.", "category": "ml"},
            # Document 7: About Scikit-learn
            
            {"id": "doc8", "text": "TensorFlow and PyTorch are deep learning frameworks.", "category": "ml"},
            # Document 8: About deep learning frameworks
            
            {"id": "doc9", "text": "Python has a large standard library included by default.", "category": "features"},
            # Document 9: About Python features
            
            {"id": "doc10", "text": "Python supports multiple programming paradigms.", "category": "features"}
            # Document 10: About Python paradigms
        ]
        # Each document is a dictionary with id, text, and category
        
        print(f"\nğŸ“š Indexing {len(documents)} documents...")
        print("-" * 60)
        # Shows how many documents will be indexed
        
        # Generate embeddings and prepare for upsert
        vectors_to_upsert = []
        # Creates empty list to store vectors and their metadata
        
        for doc in documents:
        # Loops through each document
        
            print(f"   Processing: {doc['id']}")
            # Shows which document is being processed
            
            # Generate embedding
            result = genai.embed_content(
            # Calls Gemini API to generate embedding
            
                model="models/embedding-001",
                # Uses Gemini's embedding model
                
                content=doc['text'],
                # Embeds the document text
                
                task_type="retrieval_document"
                # Specifies this is for document retrieval (optimizes embedding)
            )
            
            embedding = result['embedding']
            # Extracts the embedding vector from the result
            
            # Prepare vector with metadata
            vectors_to_upsert.append({
            # Adds to the list of vectors to upload
            
                "id": doc['id'],
                # Vector ID (same as document ID)
                
                "values": embedding,
                # The actual embedding vector (768-dimensional)
                
                "metadata": {
                # Additional data stored with the vector
                
                    "text": doc['text'],
                    # Stores original text for retrieval
                    
                    "category": doc['category']
                    # Stores category for filtering
                }
            })
            # Completes the vector dictionary
        
        # Upsert to Pinecone
        print("\nâ³ Uploading to Pinecone...")
        # Informs user about upload
        
        index.upsert(vectors=vectors_to_upsert)
        # Uploads all vectors to Pinecone at once (upsert = insert or update)
        
        print("âœ… Upload complete!")
        # Confirms successful upload
        
        # Wait for indexing
        time.sleep(2)
        # Pauses to allow Pinecone to index the vectors
        
        # Get stats
        stats = index.describe_index_stats()
        # Gets updated index statistics
        
        print(f"\nğŸ“Š Index now contains {stats['total_vector_count']} vectors")
        # Shows total vector count in index
        
        return True
        # Returns True to indicate success
        
    except ImportError:
    # Handles missing Pinecone library
    
        print("âŒ Pinecone library not installed")
        
    except Exception as e:
    # Handles any other errors
    
        print(f"âŒ Error indexing documents: {e}")
        return False
        # Returns False to indicate failure


# ============================================================================
# SECTION 5: Querying Pinecone
# ============================================================================

def query_pinecone():
# Defines function to search the Pinecone index

    """
    Search the Pinecone index
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 5: Querying Pinecone")
    print("=" * 60)
    # Prints section header
    
    try:
    # Starts error handling
    
        from pinecone import Pinecone
        # Imports Pinecone client
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets API key from environment
        
        if not api_key:
        # Checks if API key is missing
        
            print("âš ï¸  Pinecone API key not configured")
            return
            # Exits if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client
        
        index = pc.Index("rag-demo-index")
        # Connects to the demo index
        
        # Test queries
        queries = [
        # Creates list of test questions
        
            "Who created Python?",
            # Question 1: About Python creator
            
            "What frameworks can I use for web development?",
            # Question 2: About web frameworks
            
            "Tell me about data science libraries"
            # Question 3: About data science tools
        ]
        
        for query in queries:
        # Loops through each test query
        
            print(f"\n{'='*60}")
            print(f"ğŸ” Query: '{query}'")
            print(f"{'='*60}")
            # Displays the current query with decorative formatting
            
            # Generate query embedding
            query_result = genai.embed_content(
            # Generates embedding for the query
            
                model="models/embedding-001",
                # Uses same embedding model as documents
                
                content=query,
                # Embeds the query text
                
                task_type="retrieval_query"
                # Specifies this is a query (not a document)
            )
            
            query_embedding = query_result['embedding']
            # Extracts the query embedding vector
            
            # Search Pinecone
            print("\nâ³ Searching Pinecone...")
            # Informs user search is happening
            
            results = index.query(
            # Performs similarity search in Pinecone
            
                vector=query_embedding,
                # Provides the query vector to search for
                
                top_k=3,
                # Returns top 3 most similar vectors
                
                include_metadata=True
                # Includes stored metadata (text and category) in results
            )
            
            # Display results
            print(f"\nâœ… Found {len(results['matches'])} matches:\n")
            # Shows how many matches were found
            
            for i, match in enumerate(results['matches'], 1):
            # Loops through results with index starting at 1
            
                score = match['score']
                # Extracts similarity score (0-1, higher is more similar)
                
                text = match['metadata']['text']
                # Extracts the original document text from metadata
                
                category = match['metadata']['category']
                # Extracts the document category
                
                print(f"{i}. [Score: {score:.4f}] [Category: {category}]")
                # Displays result number, score (4 decimal places), and category
                
                print(f"   {text}\n")
                # Displays the actual document text
        
    except ImportError:
    # Handles missing Pinecone library
    
        print("âŒ Pinecone library not installed")
        
    except Exception as e:
    # Handles any other errors
    
        print(f"âŒ Error querying: {e}")


# ============================================================================
# SECTION 6: Complete RAG with Pinecone
# ============================================================================

def complete_rag_pinecone():
# Defines function for full RAG pipeline using Pinecone

    """
    Full RAG pipeline using Pinecone
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 6: Complete RAG Pipeline with Pinecone")
    print("=" * 60)
    # Prints section header
    
    try:
    # Starts error handling
    
        from pinecone import Pinecone
        # Imports Pinecone client
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets Pinecone API key
        
        if not api_key:
        # Checks if API key exists
        
            print("âš ï¸  Pinecone API key not configured")
            return
            # Exits if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client instance
        
        index = pc.Index("rag-demo-index")
        # Connects to the demo index
        
        model = genai.GenerativeModel('gemini-pro')
        # Creates a Gemini Pro model instance for text generation
        
        def rag_with_pinecone(question: str, top_k: int = 3):
        # Defines inner function for RAG pipeline
        # Parameters: question (user's question), top_k (number of results, default 3)
        
            """Complete RAG pipeline with Pinecone"""
            # Inner function docstring
            
            print(f"\n{'='*60}")
            print(f"â“ Question: {question}")
            print(f"{'='*60}")
            # Displays the question being processed
            
            # Step 1: Generate query embedding
            print("\n1ï¸âƒ£ Generating query embedding...")
            # Shows first step of RAG pipeline
            
            query_result = genai.embed_content(
            # Generates embedding for user's question
            
                model="models/embedding-001",
                # Uses embedding model
                
                content=question,
                # Embeds the question
                
                task_type="retrieval_query"
                # Specifies this is a query embedding
            )
            
            query_embedding = query_result['embedding']
            # Extracts the embedding vector
            
            print("   âœ… Embedding generated")
            # Confirms completion of step 1
            
            # Step 2: Search Pinecone
            print("\n2ï¸âƒ£ Searching Pinecone index...")
            # Shows second step
            
            results = index.query(
            # Searches Pinecone for similar documents
            
                vector=query_embedding,
                # Uses query embedding for search
                
                top_k=top_k,
                # Returns specified number of results
                
                include_metadata=True
                # Includes metadata in results
            )
            
            print(f"   âœ… Found {len(results['matches'])} matches")
            # Shows how many relevant documents were found
            
            # Step 3: Extract context
            print("\n3ï¸âƒ£ Building context from results...")
            # Shows third step
            
            contexts = []
            # Creates empty list for context strings
            
            for match in results['matches']:
            # Loops through each search result
            
                text = match['metadata']['text']
                # Extracts document text
                
                score = match['score']
                # Extracts similarity score
                
                contexts.append(f"[Relevance: {score:.2f}] {text}")
                # Adds formatted text with relevance score to contexts list
            
            context = "\n".join(contexts)
            # Joins all context strings with newlines
            
            print(f"   âœ… Context prepared ({len(contexts)} documents)")
            # Confirms context building is complete
            
            # Step 4: Generate response
            print("\n4ï¸âƒ£ Generating AI response...")
            # Shows fourth step
            
            prompt = f"""Based on the following context, answer the question.

Context:
{context}

Question: {question}

Answer: Provide a clear answer based on the context. Cite relevant information."""
            # Creates prompt for LLM using retrieved context and user question
            # Uses f-string to insert context and question
            
            response = model.generate_content(prompt)
            # Generates AI response using Gemini Pro
            
            print("   âœ… Response generated")
            # Confirms response generation is complete
            
            # Display results
            print(f"\n{'='*60}")
            print("ğŸ“„ RETRIEVED CONTEXT:")
            print(f"{'='*60}")
            # Prints header for context section
            
            for i, ctx in enumerate(contexts, 1):
            # Loops through context strings with numbering
            
                print(f"\n{i}. {ctx}")
                # Displays each context piece
            
            print(f"\n{'='*60}")
            print("ğŸ¤– AI RESPONSE:")
            print(f"{'='*60}")
            # Prints header for AI response section
            
            print(response.text)
            # Displays the generated answer
            
            print()
            # Prints blank line for spacing
            
            return response.text
            # Returns the response text
        
        # Test questions
        test_questions = [
        # Creates list of questions to test the RAG pipeline
        
            "What is Python known for?",
            # Question 1: General Python question
            
            "Which Python frameworks should I use for web development?",
            # Question 2: About web frameworks
            
            "What libraries are available for machine learning?"
            # Question 3: About ML libraries
        ]
        
        for question in test_questions:
        # Loops through each test question
        
            rag_with_pinecone(question)
            # Calls the RAG pipeline function for each question
            
            time.sleep(1)  # Brief pause between queries
            # Pauses 1 second between queries to avoid rate limits
        
    except ImportError:
    # Handles missing Pinecone library
    
        print("âŒ Pinecone library not installed")
        
    except Exception as e:
    # Handles any other errors
    
        print(f"âŒ Error in RAG pipeline: {e}")


# ============================================================================
# SECTION 7: Metadata Filtering
# ============================================================================

def metadata_filtering():
# Defines function to demonstrate filtering by metadata

    """
    Demonstrate metadata filtering in Pinecone
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 7: Metadata Filtering")
    print("=" * 60)
    # Prints section header
    
    print("""
    ğŸ·ï¸ METADATA FILTERING:
    
    Pinecone allows filtering by metadata BEFORE similarity search.
    This enables:
    â€¢ Search within specific categories
    â€¢ Filter by date, author, source
    â€¢ Permissions-based access
    â€¢ Multi-tenant applications
    
    Example filters:
    â€¢ {"category": "data-science"}
    â€¢ {"date": {"$gte": "2023-01-01"}}
    â€¢ {"author": "John Doe"}
    """)
    # Prints explanation of metadata filtering
    
    try:
    # Starts error handling
    
        from pinecone import Pinecone
        # Imports Pinecone client
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets API key
        
        if not api_key:
        # Checks if API key exists
        
            print("\nâš ï¸  Pinecone API key not configured")
            return
            # Exits if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client
        
        index = pc.Index("rag-demo-index")
        # Connects to demo index
        
        query = "Tell me about Python"
        # Sets the query text
        
        # Generate query embedding
        query_result = genai.embed_content(
        # Generates embedding for the query
        
            model="models/embedding-001",
            # Uses embedding model
            
            content=query,
            # Embeds the query
            
            task_type="retrieval_query"
            # Specifies query type
        )
        
        query_embedding = query_result['embedding']
        # Extracts embedding vector
        
        # Test different filters
        filters = [
        # Creates list of filter configurations to test
        
            (None, "No filter (all categories)"),
            # First test: No filter, searches all documents
            
            ({"category": "frameworks"}, "Only 'frameworks'"),
            # Second test: Only documents with category="frameworks"
            
            ({"category": "data-science"}, "Only 'data-science'")
            # Third test: Only documents with category="data-science"
        ]
        # Each tuple contains (filter_dict, description)
        
        for filter_dict, description in filters:
        # Loops through each filter configuration
        
            print(f"\n{'='*60}")
            print(f"ğŸ” {description}")
            print(f"{'='*60}")
            # Displays which filter is being used
            
            results = index.query(
            # Performs search with current filter
            
                vector=query_embedding,
                # Uses same query embedding
                
                top_k=3,
                # Returns top 3 results
                
                include_metadata=True,
                # Includes metadata in results
                
                filter=filter_dict
                # Applies the current filter (or None for no filter)
            )
            
            print(f"\nFound {len(results['matches'])} results:\n")
            # Shows number of results after filtering
            
            for i, match in enumerate(results['matches'], 1):
            # Loops through results
            
                text = match['metadata']['text']
                # Extracts document text
                
                category = match['metadata']['category']
                # Extracts category
                
                score = match['score']
                # Extracts similarity score
                
                print(f"{i}. [{category}] (score: {score:.4f})")
                # Displays result with category and score
                
                print(f"   {text}\n")
                # Displays document text
        
    except ImportError:
    # Handles missing library
    
        print("âŒ Pinecone library not installed")
        
    except Exception as e:
    # Handles other errors
    
        print(f"âŒ Error: {e}")


# ============================================================================
# SECTION 8: Production Best Practices
# ============================================================================

def production_best_practices():
# Defines function to display production best practices

    """
    Best practices for production RAG with Pinecone
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 8: Production Best Practices")
    print("=" * 60)
    # Prints section header
    
    practices = """
    âœ… INDEXING STRATEGY:
    
    1. Batch Operations
       â€¢ Upsert in batches (100-1000 vectors)
       â€¢ Parallel processing for speed
       â€¢ Use async operations when possible
    
    2. Metadata Design
       â€¢ Keep metadata small
       â€¢ Index frequently filtered fields
       â€¢ Include source information
       â€¢ Add timestamps
    
    3. ID Management
       â€¢ Use meaningful, unique IDs
       â€¢ Include source in ID (e.g., "doc1_chunk3")
       â€¢ Enable easy updates/deletes
    
    
    âœ… SEARCH OPTIMIZATION:
    
    1. Top-K Selection
       â€¢ Start with 3-5
       â€¢ Increase if needed
       â€¢ Balance relevance vs cost
    
    2. Reranking
       â€¢ Retrieve more (e.g., 20)
       â€¢ Rerank to get best 3-5
       â€¢ Improves precision
    
    3. Caching
       â€¢ Cache common queries
       â€¢ Cache embeddings
       â€¢ Use CDN for static content
    
    
    âœ… SCALING:
    
    1. Index Organization
       â€¢ Use namespaces for logical separation
       â€¢ Separate indexes for different domains
       â€¢ Consider multi-index architecture
    
    2. Performance Monitoring
       â€¢ Track query latency
       â€¢ Monitor index size
       â€¢ Watch API usage
       â€¢ Set up alerts
    
    3. Cost Management
       â€¢ Right-size your plan
       â€¢ Monitor vector counts
       â€¢ Delete unused data
       â€¢ Use serverless efficiently
    
    
    âœ… RELIABILITY:
    
    1. Error Handling
       â€¢ Retry logic with backoff
       â€¢ Handle API errors gracefully
       â€¢ Fallback strategies
       â€¢ Circuit breakers
    
    2. Testing
       â€¢ Unit tests for components
       â€¢ Integration tests
       â€¢ Load testing
       â€¢ Relevance evaluation
    
    3. Monitoring
       â€¢ Query success rate
       â€¢ Retrieval quality
       â€¢ Response times
       â€¢ User satisfaction
    
    
    âœ… SECURITY:
    
    1. Access Control
       â€¢ Use API keys properly
       â€¢ Rotate keys regularly
       â€¢ Implement authentication
       â€¢ Use namespaces for isolation
    
    2. Data Privacy
       â€¢ Encrypt sensitive data
       â€¢ PII handling
       â€¢ Compliance (GDPR, etc.)
       â€¢ Data retention policies
    
    3. Rate Limiting
       â€¢ Implement request limits
       â€¢ Prevent abuse
       â€¢ Fair usage policies
    
    
    ğŸ’¡ EXAMPLE PRODUCTION ARCHITECTURE:
    
    User Request
        â†“
    API Gateway (auth, rate limiting)
        â†“
    Application Server
        â†“
    â”œâ”€â†’ Cache Layer (Redis)
    â”œâ”€â†’ Embedding Service
    â”‚       â†“
    â””â”€â†’ Pinecone Index
        â†“
    LLM Service (Gemini)
        â†“
    Response
        â†“
    Logging & Monitoring
    
    
    ğŸ“Š METRICS TO TRACK:
    
    â€¢ Query latency (p50, p95, p99)
    â€¢ Retrieval precision @ k
    â€¢ Answer quality scores
    â€¢ Cache hit rate
    â€¢ API costs
    â€¢ Error rates
    â€¢ User satisfaction (feedback)
    
    
    ğŸ”§ MAINTENANCE:
    
    1. Regular Updates
       â€¢ Add new documents
       â€¢ Remove outdated content
       â€¢ Update embeddings if model changes
    
    2. Performance Tuning
       â€¢ Optimize chunk sizes
       â€¢ Adjust top-k
       â€¢ Refine metadata
       â€¢ A/B test changes
    
    3. Documentation
       â€¢ Index schema
       â€¢ Metadata fields
       â€¢ Query patterns
       â€¢ Runbooks for issues
    """
    # Multi-line string containing comprehensive production best practices
    # Covers indexing, search, scaling, reliability, security, architecture, and maintenance
    
    print(practices)
    # Displays all best practices


# ============================================================================
# SECTION 9: Cleanup
# ============================================================================

def cleanup_demo():
# Defines function to clean up demo resources

    """
    Clean up demo resources
    """
    # Function docstring
    
    print("\n" + "=" * 60)
    print("SECTION 9: Cleanup")
    print("=" * 60)
    # Prints section header
    
    try:
    # Starts error handling
    
        from pinecone import Pinecone
        # Imports Pinecone client
        
        api_key = os.getenv('PINECONE_API_KEY')
        # Gets API key
        
        if not api_key:
        # Checks if API key exists
        
            print("âš ï¸  Pinecone API key not configured")
            return
            # Exits if no API key
        
        pc = Pinecone(api_key=api_key)
        # Creates Pinecone client
        
        index_name = "rag-demo-index"
        # Sets the index name to delete
        
        choice = input(f"\nâš ï¸  Delete index '{index_name}'? (yes/no): ").strip().lower()
        # Asks user for confirmation (gets input, strips whitespace, converts to lowercase)
        
        if choice == 'yes':
        # Checks if user confirmed deletion
        
            print("\nâ³ Deleting index...")
            # Informs user deletion is happening
            
            pc.delete_index(index_name)
            # Deletes the specified index
            
            print("âœ… Index deleted successfully!")
            # Confirms deletion
            
            print("\nğŸ’¡ You can recreate it anytime by running the setup sections")
            # Provides helpful tip
            
        else:
        # If user didn't type 'yes'
        
            print("\nâœ… Index preserved")
            # Informs user index was kept
            
            print("\nğŸ’¡ To manually delete later:")
            print(f"   pc.delete_index('{index_name}')")
            # Shows how to delete manually if needed
        
    except ImportError:
    # Handles missing library
    
        print("âŒ Pinecone library not installed")
        
    except Exception as e:
    # Handles other errors
    
        print(f"âŒ Error: {e}")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
# Defines the main function that provides interactive menu

    """
    Main function with menu
    """
    # Function docstring
    
    print("\n")
    print("ğŸ“ " + "=" * 58 + " ğŸ“")
    print("    GENERATIVE AI SESSION - MODULE 10: RAG WITH PINECONE")
    print("ğŸ“ " + "=" * 58 + " ğŸ“")
    # Prints decorative program header
    
    menu = """
    Choose a section to run:
    
    1. Understanding Vector Databases
    2. Pinecone Setup Guide
    3. Create Pinecone Index
    4. Index Documents
    5. Query Pinecone
    6. Complete RAG Pipeline
    7. Metadata Filtering
    8. Production Best Practices
    9. Cleanup (Delete Demo Index)
    
    setup - Run setup (sections 2-4)
    demo - Run demo (sections 5-7)
    all - Run all (except cleanup)
    quit - Exit
    
    """
    # Multi-line string containing menu options
    
    while True:
    # Infinite loop for menu (exits when user chooses quit)
    
        print(menu)
        # Displays menu options
        
        choice = input("Your choice: ").strip().lower()
        # Gets user input, strips whitespace, converts to lowercase
        
        if choice in ['quit', 'q', 'exit']:
        # Checks if user wants to exit
        
            print("ğŸ‘‹ Goodbye!")
            break
            # Exits the loop (ends program)
            
        elif choice == '1':
        # If user chose option 1
        
            vector_database_concepts()
            # Calls function for section 1
            
        elif choice == '2':
        # If user chose option 2
        
            pinecone_setup_guide()
            # Calls function for section 2
            
        elif choice == '3':
        # If user chose option 3
        
            create_pinecone_index()
            # Calls function for section 3
            
        elif choice == '4':
        # If user chose option 4
        
            index_documents()
            # Calls function for section 4
            
        elif choice == '5':
        # If user chose option 5
        
            query_pinecone()
            # Calls function for section 5
            
        elif choice == '6':
        # If user chose option 6
        
            complete_rag_pinecone()
            # Calls function for section 6
            
        elif choice == '7':
        # If user chose option 7
        
            metadata_filtering()
            # Calls function for section 7
            
        elif choice == '8':
        # If user chose option 8
        
            production_best_practices()
            # Calls function for section 8
            
        elif choice == '9':
        # If user chose option 9
        
            cleanup_demo()
            # Calls function for section 9
            
        elif choice == 'setup':
        # If user chose 'setup' (runs sections 2-4)
        
            print("\nğŸ”§ Running setup sequence...")
            # Informs user setup is starting
            
            if pinecone_setup_guide():
            # Runs setup guide and checks if it returned True (successful connection)
            
                create_pinecone_index()
                # Creates the index
                
                index_documents()
                # Indexes sample documents
                
            print("\nâœ… Setup complete!")
            # Confirms setup is done
            
        elif choice == 'demo':
        # If user chose 'demo' (runs sections 5-7)
        
            print("\nğŸ¬ Running demo sequence...")
            # Informs user demo is starting
            
            query_pinecone()
            # Runs query demo
            
            complete_rag_pinecone()
            # Runs RAG pipeline demo
            
            metadata_filtering()
            # Runs filtering demo
            
            print("\nâœ… Demo complete!")
            # Confirms demo is done
            
        elif choice == 'all':
        # If user chose 'all' (runs everything except cleanup)
        
            vector_database_concepts()
            # Runs section 1
            
            if pinecone_setup_guide():
            # Runs section 2 and checks if successful
            
                create_pinecone_index()
                # Runs section 3
                
                index_documents()
                # Runs section 4
                
                query_pinecone()
                # Runs section 5
                
                complete_rag_pinecone()
                # Runs section 6
                
                metadata_filtering()
                # Runs section 7
                
            production_best_practices()
            # Runs section 8
            
            print("\nâœ… All sections completed!")
            # Confirms all sections are done
            
            break
            # Exits the loop after running all
            
        else:
        # If user entered invalid choice
        
            print("âš ï¸  Invalid choice. Please try again.")
            # Displays error message and loop continues


if __name__ == "__main__":
# Checks if this script is being run directly (not imported as module)

    main()
    # Calls the main function to start the program
    
    # Teaching Questions:
    # 1. Why use a vector database vs in-memory search?
    # 2. How does metadata filtering improve RAG?
    # 3. What are key considerations for production RAG?
    # Comments listing teaching questions for students
```

---

## ASCII Flow Diagram

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    RAG WITH PINECONE - COMPLETE FLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SETUP PHASE (ONE-TIME)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Load .env file  â”‚ â—„â”€â”€â”€ Contains GOOGLE_API_KEY and PINECONE_API_KEY
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Configure APIs  â”‚
    â”‚  - Google AI    â”‚
    â”‚  - Pinecone     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Create Pinecone Index  â”‚
    â”‚  Name: rag-demo-index  â”‚
    â”‚  Dimension: 768        â”‚
    â”‚  Metric: cosine        â”‚
    â”‚  Cloud: AWS            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Prepare Sample Documents     â”‚
    â”‚  - Python intro              â”‚
    â”‚  - Django & Flask            â”‚
    â”‚  - NumPy & Pandas            â”‚
    â”‚  - ML libraries              â”‚
    â”‚  (10 docs with metadata)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ For Each Document:           â”‚
    â”‚  1. Extract text             â”‚
    â”‚  2. Generate embedding       â”‚
    â”‚     (Gemini embedding-001)   â”‚
    â”‚  3. Add to upsert list       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Upsert Vectors to Pinecone   â”‚
    â”‚  - Send all vectors          â”‚
    â”‚  - Include metadata          â”‚
    â”‚  - Wait for indexing         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUERY PHASE (PER USER REQUEST)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   User asks a question       â”‚
    â”‚   "Who created Python?"      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 1: Generate Query       â”‚
    â”‚         Embedding            â”‚
    â”‚                              â”‚
    â”‚  Input: User question        â”‚
    â”‚  Model: embedding-001        â”‚
    â”‚  Task: retrieval_query       â”‚
    â”‚  Output: 768-dim vector      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 2: Search Pinecone      â”‚
    â”‚                              â”‚
    â”‚  index.query(                â”‚
    â”‚    vector=query_embedding,   â”‚
    â”‚    top_k=3,                  â”‚
    â”‚    include_metadata=True,    â”‚
    â”‚    filter={...}  # optional  â”‚
    â”‚  )                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚  Pinecone performs:
             â”‚  - ANN search
             â”‚  - Applies filters
             â”‚  - Ranks by similarity
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 3: Retrieve Results     â”‚
    â”‚                              â”‚
    â”‚  Top 3 similar documents:    â”‚
    â”‚  1. Score: 0.89              â”‚
    â”‚     Text: "Python is..."     â”‚
    â”‚     Category: intro          â”‚
    â”‚  2. Score: 0.76              â”‚
    â”‚     Text: "Python has..."    â”‚
    â”‚     Category: features       â”‚
    â”‚  3. Score: 0.72              â”‚
    â”‚     Text: "Python supports"  â”‚
    â”‚     Category: features       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 4: Build Context        â”‚
    â”‚                              â”‚
    â”‚  Concatenate retrieved       â”‚
    â”‚  documents with scores:      â”‚
    â”‚                              â”‚
    â”‚  "[Relevance: 0.89]          â”‚
    â”‚   Python is a high-level..." â”‚
    â”‚  "[Relevance: 0.76]          â”‚
    â”‚   Python has a large..."     â”‚
    â”‚  "[Relevance: 0.72]          â”‚
    â”‚   Python supports..."        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 5: Generate Prompt      â”‚
    â”‚                              â”‚
    â”‚  "Based on the following     â”‚
    â”‚   context, answer...         â”‚
    â”‚                              â”‚
    â”‚   Context: [retrieved docs]  â”‚
    â”‚                              â”‚
    â”‚   Question: [user question]  â”‚
    â”‚                              â”‚
    â”‚   Answer: [instructions]"    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 6: Generate Response    â”‚
    â”‚                              â”‚
    â”‚  model.generate_content()    â”‚
    â”‚  using Gemini Pro            â”‚
    â”‚                              â”‚
    â”‚  LLM synthesizes answer      â”‚
    â”‚  from provided context       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 7: Display Results      â”‚
    â”‚                              â”‚
    â”‚  ğŸ“„ RETRIEVED CONTEXT:       â”‚
    â”‚  [Show 3 documents]          â”‚
    â”‚                              â”‚
    â”‚  ğŸ¤– AI RESPONSE:             â”‚
    â”‚  "Python was created by      â”‚
    â”‚   Guido van Rossum..."       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      METADATA FILTERING VARIANT                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ User Question + Filter       â”‚
    â”‚ "Tell me about Python"       â”‚
    â”‚ Filter: {category: "ml"}     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Generate Query Embedding     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Search with Filter           â”‚
    â”‚                              â”‚
    â”‚  Pinecone first filters:     â”‚
    â”‚  âœ“ Only docs where           â”‚
    â”‚    category == "ml"          â”‚
    â”‚                              â”‚
    â”‚  Then searches filtered set  â”‚
    â”‚  for similarity              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Returns ONLY ML docs         â”‚
    â”‚  - Scikit-learn              â”‚
    â”‚  - TensorFlow & PyTorch      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA STRUCTURES                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Document (Python dict):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                    â”‚
â”‚   "id": "doc1",                      â”‚
â”‚   "text": "Python is a high-level   â”‚
â”‚            programming language...", â”‚
â”‚   "category": "intro"                â”‚
â”‚ }                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Vector (for Pinecone):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                                        â”‚
â”‚   "id": "doc1",                                          â”‚
â”‚   "values": [0.023, -0.156, 0.891, ..., 0.432],        â”‚
â”‚   "metadata": {                                          â”‚
â”‚     "text": "Python is a high-level...",                â”‚
â”‚     "category": "intro"                                  â”‚
â”‚   }                                                      â”‚
â”‚ }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query Result (from Pinecone):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                                        â”‚
â”‚   "matches": [                                           â”‚
â”‚     {                                                    â”‚
â”‚       "id": "doc1",                                      â”‚
â”‚       "score": 0.89,                                     â”‚
â”‚       "metadata": {                                      â”‚
â”‚         "text": "Python is...",                          â”‚
â”‚         "category": "intro"                              â”‚
â”‚       }                                                  â”‚
â”‚     },                                                   â”‚
â”‚     {...},                                               â”‚
â”‚     {...}                                                â”‚
â”‚   ]                                                      â”‚
â”‚ }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPONENT RELATIONSHIPS                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚        Your Application                   â”‚
             â”‚    (10_rag_pinecone.py)                   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ dotenv â”‚    â”‚ Gemini   â”‚    â”‚ Pinecone â”‚
    â”‚ (.env) â”‚    â”‚   API    â”‚    â”‚   API    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚
         â”‚               â”‚               â”‚
         â”‚               â–¼               â–¼
         â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        â”‚Embedding â”‚    â”‚Vector Storageâ”‚
         â”‚        â”‚  Model   â”‚    â”‚   (Cloud)    â”‚
         â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚
         â”‚               â–¼               â”‚
         â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
         â”‚        â”‚   LLM    â”‚           â”‚
         â”‚        â”‚(Gemini   â”‚           â”‚
         â”‚        â”‚  Pro)    â”‚           â”‚
         â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
         â”‚                               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   User Output   â”‚
              â”‚   (Console)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXECUTION FLOW OPTIONS                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Main Menu Loop:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Display Menu       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Get User Choice    â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â–º '1' â”€â”€â–º vector_database_concepts()
           â”‚
           â”œâ”€â”€â–º '2' â”€â”€â–º pinecone_setup_guide()
           â”‚
           â”œâ”€â”€â–º '3' â”€â”€â–º create_pinecone_index()
           â”‚
           â”œâ”€â”€â–º '4' â”€â”€â–º index_documents()
           â”‚
           â”œâ”€â”€â–º '5' â”€â”€â–º query_pinecone()
           â”‚
           â”œâ”€â”€â–º '6' â”€â”€â–º complete_rag_pinecone()
           â”‚
           â”œâ”€â”€â–º '7' â”€â”€â–º metadata_filtering()
           â”‚
           â”œâ”€â”€â–º '8' â”€â”€â–º production_best_practices()
           â”‚
           â”œâ”€â”€â–º '9' â”€â”€â–º cleanup_demo()
           â”‚
           â”œâ”€â”€â–º 'setup' â”€â”€â–º Run sections 2-4 in sequence
           â”‚
           â”œâ”€â”€â–º 'demo' â”€â”€â–º Run sections 5-7 in sequence
           â”‚
           â”œâ”€â”€â–º 'all' â”€â”€â–º Run sections 1-8 in sequence
           â”‚
           â””â”€â”€â–º 'quit' â”€â”€â–º Exit program


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                            END OF FLOW DIAGRAM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
