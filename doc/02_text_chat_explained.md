# Module 02 - Text Chat - Detailed Code Explanation

This document explains every line of code in the Text Chat module.

---

## üìä Visual Overview: Text Chat Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     TEXT CHAT MODULE FLOW                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    Setup Phase                Processing Phase              Output Phase
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ               ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ             ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Import       ‚îÇ           ‚îÇ   User writes    ‚îÇ          ‚îÇ   Display    ‚îÇ
‚îÇ Libraries    ‚îÇ    ‚îÄ‚îÄ‚Üí    ‚îÇ   a prompt       ‚îÇ    ‚îÄ‚îÄ‚Üí   ‚îÇ   Response   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                            ‚îÇ                            ‚îÇ
       ‚ñº                            ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load .env    ‚îÇ           ‚îÇ  Send to Gemini  ‚îÇ          ‚îÇ  Parse Text  ‚îÇ
‚îÇ Configure    ‚îÇ           ‚îÇ  via API call    ‚îÇ          ‚îÇ  Format for  ‚îÇ
‚îÇ API Key      ‚îÇ           ‚îÇ                  ‚îÇ          ‚îÇ  Display     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                            ‚îÇ                            ‚îÇ
       ‚ñº                            ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Create Model ‚îÇ           ‚îÇ AI processes &   ‚îÇ          ‚îÇ   User sees  ‚îÇ
‚îÇ Instance     ‚îÇ           ‚îÇ generates text   ‚îÇ          ‚îÇ   Result!    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Prompt Engineering: Quality Levels

```
Prompt Quality Impact on Response:

‚ùå POOR PROMPT:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "tell me about dogs"    ‚îÇ  ‚îÄ‚îÄ‚Üí  Vague, generic response
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        (200 words, unfocused)

‚ö†Ô∏è OKAY PROMPT:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "write about dog breeds"        ‚îÇ  ‚îÄ‚îÄ‚Üí  Better, but still broad
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        (better focus)

‚úÖ GREAT PROMPT:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "Write a 100-word paragraph about Golden Retrievers          ‚îÇ
‚îÇ  focusing on their temperament and family compatibility.     ‚îÇ
‚îÇ  Use friendly tone for pet owners."                          ‚îÇ  ‚îÄ‚îÄ‚Üí  Specific,
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     high-quality
                                                                       response!

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  KEY ELEMENTS OF GOOD PROMPTS:                                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                  ‚îÇ
‚îÇ  ‚úì Specific topic/scope                                           ‚îÇ
‚îÇ  ‚úì Desired length/format                                          ‚îÇ
‚îÇ  ‚úì Tone/style guidance                                            ‚îÇ
‚îÇ  ‚úì Target audience                                                ‚îÇ
‚îÇ  ‚úì Any constraints                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ 7 Text Generation Use Cases

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  This module demonstrates 7 different ways to use text AI:    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1Ô∏è‚É£ SIMPLE TEXT GENERATION
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Basic Prompt ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Simple Reply ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

2Ô∏è‚É£ QUESTION ANSWERING
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Ask Question ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Get Answer   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

3Ô∏è‚É£ CREATIVE WRITING
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Story Prompt ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Creative Text‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

4Ô∏è‚É£ SUMMARIZATION
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Long Article ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Short Summary‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

5Ô∏è‚É£ TRANSLATION
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ English Text ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Spanish Text ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

6Ô∏è‚É£ CODE GENERATION
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Code Request ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ  ‚îÄ‚îÄ‚Üí ‚îÇ Python Code  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

7Ô∏è‚É£ INTERACTIVE CHAT
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Multi-turn   ‚îÇ  ‚áÑ  ‚îÇ  Gemini  ‚îÇ  ‚áÑ  ‚îÇ Conversation ‚îÇ
   ‚îÇ Dialog       ‚îÇ      ‚îÇ          ‚îÇ      ‚îÇ with Memory  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üèóÔ∏è Code Structure Map

```
02_text_chat.py
‚îÇ
‚îú‚îÄ‚îÄ üì¶ IMPORTS
‚îÇ   ‚îú‚îÄ‚îÄ os
‚îÇ   ‚îú‚îÄ‚îÄ dotenv
‚îÇ   ‚îî‚îÄ‚îÄ google.generativeai
‚îÇ
‚îú‚îÄ‚îÄ üîß SETUP (runs immediately)
‚îÇ   ‚îú‚îÄ‚îÄ load_dotenv()
‚îÇ   ‚îî‚îÄ‚îÄ genai.configure()
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 1: simple_text_generation()
‚îÇ   ‚îî‚îÄ‚îÄ Basic "Hello" prompt ‚Üí Response
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 2: question_answering()
‚îÇ   ‚îú‚îÄ‚îÄ Technical question
‚îÇ   ‚îú‚îÄ‚îÄ Historical question
‚îÇ   ‚îî‚îÄ‚îÄ Comparison question
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 3: creative_writing()
‚îÇ   ‚îú‚îÄ‚îÄ Story generation
‚îÇ   ‚îú‚îÄ‚îÄ Poetry generation
‚îÇ   ‚îî‚îÄ‚îÄ Professional writing
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 4: summarization_examples()
‚îÇ   ‚îú‚îÄ‚îÄ Article summary
‚îÇ   ‚îî‚îÄ‚îÄ Technical summary
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 5: translation_examples()
‚îÇ   ‚îú‚îÄ‚îÄ English ‚Üí Spanish
‚îÇ   ‚îî‚îÄ‚îÄ English ‚Üí French
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 6: code_generation_examples()
‚îÇ   ‚îú‚îÄ‚îÄ Function generation
‚îÇ   ‚îî‚îÄ‚îÄ Class generation
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 7: practical_use_cases()
‚îÇ   ‚îú‚îÄ‚îÄ Email writing
‚îÇ   ‚îú‚îÄ‚îÄ Document formatting
‚îÇ   ‚îî‚îÄ‚îÄ Data extraction
‚îÇ
‚îú‚îÄ‚îÄ üéØ FUNCTION 8: interactive_chat()
‚îÇ   ‚îî‚îÄ‚îÄ Multi-turn conversation with memory
‚îÇ
‚îî‚îÄ‚îÄ üöÄ MAIN MENU SYSTEM
    ‚îú‚îÄ‚îÄ Display options
    ‚îú‚îÄ‚îÄ Get user choice
    ‚îî‚îÄ‚îÄ Call selected function
```

---

## üí¨ How Text Generation Works (Step-by-Step)

```
STEP 1: CREATE MODEL
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
model = genai.GenerativeModel('gemini-2.0-flash')
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Model Ready  ‚îÇ
    ‚îÇ to Accept    ‚îÇ
    ‚îÇ Prompts      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

STEP 2: WRITE PROMPT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
prompt = "Explain quantum computing in simple terms"
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Text String  ‚îÇ
    ‚îÇ Describing   ‚îÇ
    ‚îÇ Your Request ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

STEP 3: GENERATE CONTENT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
response = model.generate_content(prompt)
              ‚îÇ
              ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  API Call to Google Servers    ‚îÇ
       ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ
       ‚îÇ  1. Tokenize prompt            ‚îÇ
       ‚îÇ  2. Process through neural net ‚îÇ
       ‚îÇ  3. Generate response tokens   ‚îÇ
       ‚îÇ  4. Decode to text             ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Response Object Created       ‚îÇ
    ‚îÇ Contains:                     ‚îÇ
    ‚îÇ - .text (the generated text)  ‚îÇ
    ‚îÇ - .candidates (alternatives)  ‚îÇ
    ‚îÇ - metadata                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

STEP 4: USE RESPONSE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
print(response.text)
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Display on Screen   ‚îÇ
‚îÇ OR                  ‚îÇ
‚îÇ Save to File        ‚îÇ
‚îÇ OR                  ‚îÇ
‚îÇ Process Further     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Interactive Chat: Conversation Memory

```
Regular Generation (No Memory):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Prompt 1 ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ Reply 1  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚úó Memory cleared!
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Prompt 2 ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ  Gemini  ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ Reply 2  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                 ‚ö†Ô∏è Cannot reference Prompt 1!


Chat Session (With Memory):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Message 1‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ  Chat Session    ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ Reply 1  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ  History: []     ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                    ‚úÖ History saved:
                    ["User: Msg 1", "AI: Reply 1"]
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Message 2‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ  Chat Session    ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ Reply 2  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ  History: [...]  ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                    ‚úÖ Can reference previous messages!


Implementation:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

chat = model.start_chat(history=[])
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Chat Object with Memory          ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ            ‚îÇ
‚îÇ  - Stores conversation history    ‚îÇ
‚îÇ  - Maintains context               ‚îÇ
‚îÇ  - Each message aware of previous ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

response = chat.send_message("Hello")
              ‚îÇ
              ‚ñº
        Automatically:
        1. Appends user message to history
        2. Sends ENTIRE history to API
        3. Gets contextual response
        4. Appends AI response to history
```

---

## üìê Prompt Structure Examples

```
BASIC STRUCTURE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Action Verb] + [Topic]       ‚îÇ
‚îÇ                                ‚îÇ
‚îÇ Example:                       ‚îÇ
‚îÇ "Explain quantum computing"   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


INTERMEDIATE STRUCTURE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Action] + [Topic] + [Format] ‚îÇ
‚îÇ                                ‚îÇ
‚îÇ Example:                       ‚îÇ
‚îÇ "Explain quantum computing    ‚îÇ
‚îÇ  in 3 simple paragraphs"      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


ADVANCED STRUCTURE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Context] + [Task] + [Format] +        ‚îÇ
‚îÇ [Constraints] + [Style]                 ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Example:                                ‚îÇ
‚îÇ "You are a teacher for 10-year-olds.   ‚îÇ
‚îÇ  Explain quantum computing using       ‚îÇ
‚îÇ  everyday analogies. Write 2 short     ‚îÇ
‚îÇ  paragraphs. Use simple words.         ‚îÇ
‚îÇ  Be enthusiastic and encouraging."     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ           ‚îÇ          ‚îÇ         ‚îÇ
      ‚ñº           ‚ñº          ‚ñº         ‚ñº
   Context     Task      Format    Style
```

---

## Module Documentation Block

```python
"""
02 - Text Chat
==============
```
**Explanation:** Docstring header for Module 2. The equals signs create a visual underline for the title.

```python
This module demonstrates various text generation and chat capabilities.
Students will learn:
- Simple text generation
- Question-answering
- Different prompting techniques
- Handling long-form content
- Building interactive chat
```
**Explanation:** Lists the learning objectives - what students will be able to do after this module.

```python
Teaching Points:
- Prompt engineering is crucial
- Clear, specific prompts get better results
- Context matters for quality responses
"""
```
**Explanation:** Key concepts instructors should emphasize. The closing `"""` ends the docstring.

---

## Import Statements

```python
import os
```
**Explanation:** Imports the `os` module to interact with operating system features like environment variables.

```python
from dotenv import load_dotenv
```
**Explanation:** Imports the `load_dotenv` function to read `.env` files containing configuration.

```python
import google.generativeai as genai
```
**Explanation:** Imports Google's Generative AI library with the short alias `genai`.

---

## Initial Setup

```python
# Setup
load_dotenv()
```
**Explanation:** Comment describes what follows. Loads environment variables from the `.env` file into memory.

```python
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
```
**Explanation:** Configures the Gemini API by getting the API key from environment variables. This setup happens once at module load, so it's available to all functions.

---

## Section 1: Simple Text Generation Function

```python
# ============================================================================
# SECTION 1: Simple Text Generation
# ============================================================================
```
**Explanation:** Visual separator comment to organize code sections.

```python
def simple_text_generation():
```
**Explanation:** Defines a function with no parameters. This function demonstrates basic text generation.

```python
    """
    Basic text generation - the foundation of all LLM interactions
    """
```
**Explanation:** Function docstring explaining its purpose.

```python
    print("\n" + "=" * 60)
    print("SECTION 1: Simple Text Generation")
    print("=" * 60)
```
**Explanation:** Prints section header with separators. `\n` adds blank line for spacing.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates a new GenerativeModel object for text generation. This is a local variable within this function.

```python
    # Example 1: Direct question
    print("\n1Ô∏è‚É£ Direct Question:")
```
**Explanation:** Comment labels this example. Prints a numbered header with emoji.

```python
    prompt1 = "What is machine learning in one sentence?"
```
**Explanation:** Stores the prompt text in a variable named `prompt1`. This is what we'll send to the AI.

```python
    print(f"üìù Prompt: {prompt1}")
```
**Explanation:** Shows the user what prompt we're sending. The f-string embeds the `prompt1` variable.

```python
    response1 = model.generate_content(prompt1)
```
**Explanation:** Calls the model's `generate_content` method with our prompt. Stores the response object in `response1`.

```python
    print(f"ü§ñ Response: {response1.text}\n")
```
**Explanation:** Prints the text content from the response. `.text` accesses the text property. `\n` adds a blank line after.

```python
    # Example 2: Creative writing
    print("\n2Ô∏è‚É£ Creative Writing:")
```
**Explanation:** Header for the second example showing a different use case.

```python
    prompt2 = "Write a haiku about artificial intelligence."
```
**Explanation:** A creative writing prompt asking for poetry in haiku format.

```python
    print(f"üìù Prompt: {prompt2}")
```
**Explanation:** Shows the prompt to the user.

```python
    response2 = model.generate_content(prompt2)
```
**Explanation:** Generates content for the creative prompt.

```python
    print(f"ü§ñ Response:\n{response2.text}\n")
```
**Explanation:** Prints the AI's creative response. The `\n` before `{response2.text}` puts the response on a new line.

```python
    # Example 3: Explanation
    print("\n3Ô∏è‚É£ Technical Explanation:")
```
**Explanation:** Header for the third example demonstrating explanations.

```python
    prompt3 = "Explain neural networks to a 10-year-old."
```
**Explanation:** A prompt requesting simple explanations. The "to a 10-year-old" part guides the AI to use simple language.

```python
    print(f"üìù Prompt: {prompt3}")
```
**Explanation:** Shows what we're asking.

```python
    response3 = model.generate_content(prompt3)
```
**Explanation:** Generates the explanation.

```python
    print(f"ü§ñ Response: {response3.text}\n")
```
**Explanation:** Prints the AI's simplified explanation.

---

## Section 2: Question Answering Function

```python
# ============================================================================
# SECTION 2: Question Answering
# ============================================================================
```
**Explanation:** Section separator for Q&A demonstrations.

```python
def question_answering():
```
**Explanation:** Defines function to demonstrate different types of questions.

```python
    """
    Different styles of Q&A
    """
```
**Explanation:** Brief docstring.

```python
    print("\n" + "=" * 60)
    print("SECTION 2: Question Answering")
    print("=" * 60)
```
**Explanation:** Prints section header.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates a model instance for this function.

```python
    # Example 1: Factual question
    print("\n1Ô∏è‚É£ Factual Question:")
```
**Explanation:** Labels the first question type - factual questions with verifiable answers.

```python
    prompt = "Who invented the Python programming language and when?"
```
**Explanation:** A factual question about Python's creator. Uses single variable name `prompt` since we're not reusing these.

```python
    print(f"üìù Prompt: {prompt}")
```
**Explanation:** Displays the question.

```python
    response = model.generate_content(prompt)
```
**Explanation:** Gets the answer from the AI.

```python
    print(f"ü§ñ Response: {response.text}\n")
```
**Explanation:** Prints the factual answer.

```python
    # Example 2: Comparison question
    print("\n2Ô∏è‚É£ Comparison Question:")
```
**Explanation:** Labels the second type - comparison questions that analyze differences.

```python
    prompt = "What are the key differences between supervised and unsupervised learning?"
```
**Explanation:** A question requesting comparison between two concepts.

```python
    print(f"üìù Prompt: {prompt}")
    
    response = model.generate_content(prompt)
    print(f"ü§ñ Response: {response.text}\n")
```
**Explanation:** Shows prompt, generates response, and prints answer - same pattern as before.

```python
    # Example 3: Opinion question
    print("\n3Ô∏è‚É£ Opinion-Based Question:")
```
**Explanation:** Labels the third type - questions asking for pros/cons or opinions.

```python
    prompt = "What are the pros and cons of using AI in healthcare?"
```
**Explanation:** An opinion question asking for balanced analysis.

```python
    print(f"üìù Prompt: {prompt}")
    
    response = model.generate_content(prompt)
    print(f"ü§ñ Response: {response.text}\n")
```
**Explanation:** Same pattern: show, generate, print.

---

## Section 3: Prompt Engineering Techniques

```python
# ============================================================================
# SECTION 3: Prompt Engineering Techniques
# ============================================================================
```
**Explanation:** Section separator for prompt engineering demonstrations.

```python
def prompt_engineering_examples():
```
**Explanation:** Defines function showing how prompt quality affects output quality.

```python
    """
    Demonstrate how different prompts affect output quality
    """
```
**Explanation:** Docstring describing the educational purpose.

```python
    print("\n" + "=" * 60)
    print("SECTION 3: Prompt Engineering Techniques")
    print("=" * 60)
```
**Explanation:** Section header.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates model instance.

```python
    # Technique 1: Vague vs Specific
    print("\n1Ô∏è‚É£ VAGUE vs SPECIFIC Prompts:\n")
```
**Explanation:** Labels the first technique comparison. `\n` at end adds spacing.

```python
    print("‚ùå Vague prompt:")
```
**Explanation:** Red X emoji indicates this is the bad example.

```python
    vague_prompt = "Tell me about AI."
```
**Explanation:** An overly broad, vague prompt that will get generic responses.

```python
    print(f"   '{vague_prompt}'")
```
**Explanation:** Shows the vague prompt. Spaces indent it for visual hierarchy.

```python
    response = model.generate_content(vague_prompt)
```
**Explanation:** Generates content with the vague prompt.

```python
    print(f"   Response length: {len(response.text)} characters")
```
**Explanation:** Shows character count using `len()` function. Helps demonstrate that vague prompts often get longer, less focused responses.

```python
    print(f"   Preview: {response.text[:150]}...\n")
```
**Explanation:** Shows first 150 characters using slice `[:150]`. The `...` indicates truncation. Shows quality without overwhelming output.

```python
    print("‚úÖ Specific prompt:")
```
**Explanation:** Green checkmark emoji indicates this is the good example.

```python
    specific_prompt = "List 3 practical applications of AI in education with one-sentence descriptions."
```
**Explanation:** A specific, detailed prompt that clearly states what format and content is wanted.

```python
    print(f"   '{specific_prompt}'")
```
**Explanation:** Shows the specific prompt.

```python
    response = model.generate_content(specific_prompt)
```
**Explanation:** Generates with the specific prompt.

```python
    print(f"   Response:\n{response.text}\n")
```
**Explanation:** Prints full response since specific prompts usually give concise, useful answers.

```python
    # Technique 2: Role-based prompting
    print("\n2Ô∏è‚É£ ROLE-BASED Prompting:\n")
```
**Explanation:** Header for the second technique.

```python
    role_prompt = """You are an experienced Python tutor. 
Explain what a decorator is to a beginner in simple terms with a short example."""
```
**Explanation:** Multi-line string (triple quotes) containing a role instruction. "You are..." sets the AI's persona, which affects tone and detail level.

```python
    print(f"üìù Prompt: {role_prompt}")
```
**Explanation:** Shows the role-based prompt.

```python
    response = model.generate_content(role_prompt)
    print(f"ü§ñ Response:\n{response.text}\n")
```
**Explanation:** Generates and prints the response. The role context should produce a tutor-like explanation.

```python
    # Technique 3: Step-by-step instructions
    print("\n3Ô∏è‚É£ STEP-BY-STEP Instructions:\n")
```
**Explanation:** Header for third technique.

```python
    step_prompt = """Break down the following task into steps:
How to create a simple REST API in Python using Flask.
Number each step and keep it concise."""
```
**Explanation:** Multi-line prompt asking for structured, numbered steps. Specifies both content and format.

```python
    print(f"üìù Prompt: {step_prompt}")
    response = model.generate_content(step_prompt)
    print(f"ü§ñ Response:\n{response.text}\n")
```
**Explanation:** Show, generate, print pattern - requesting step-by-step output.

```python
    # Technique 4: Format specification
    print("\n4Ô∏è‚É£ FORMAT Specification:\n")
```
**Explanation:** Header for fourth technique about specifying output format.

```python
    format_prompt = """List 3 benefits of using version control.
Format your response as:
Benefit 1: [description]
Benefit 2: [description]
Benefit 3: [description]"""
```
**Explanation:** Multi-line prompt that explicitly shows the desired output format. This ensures consistent, parseable responses.

```python
    print(f"üìù Prompt: {format_prompt}")
    response = model.generate_content(format_prompt)
    print(f"ü§ñ Response:\n{response.text}\n")
```
**Explanation:** Generate and show the formatted response.

---

## Section 4: Interactive Single-Turn Chat

```python
# ============================================================================
# SECTION 4: Interactive Chat (Single Turn)
# ============================================================================
```
**Explanation:** Section separator for interactive chat.

```python
def interactive_single_turn():
```
**Explanation:** Defines function for interactive user input, but without conversation memory.

```python
    """
    Single-turn conversation (no memory)
    """
```
**Explanation:** Docstring emphasizing this doesn't remember previous messages.

```python
    print("\n" + "=" * 60)
    print("SECTION 4: Interactive Single-Turn Chat")
    print("=" * 60)
    print("\nNote: Each question is independent (no conversation memory)")
    print("Type 'quit' to exit\n")
```
**Explanation:** Prints header and important note about no memory. Sets user expectations and shows exit command.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates model instance.

```python
    conversation_count = 0
```
**Explanation:** Initializes a counter variable to track how many messages have been sent. Starts at 0.

```python
    while True:
```
**Explanation:** Starts an infinite loop. Will continue until we explicitly `break` out of it.

```python
        user_input = input("You: ").strip()
```
**Explanation:** Uses `input()` to get text from user. The string "You: " is the prompt shown. `.strip()` removes leading/trailing whitespace.

```python
        if user_input.lower() in ['quit', 'exit', 'q']:
```
**Explanation:** Checks if user wants to exit. `.lower()` converts to lowercase so "QUIT" and "quit" both work. `in [...]` checks if the input matches any item in the list.

```python
            print("üëã Goodbye!")
            break
```
**Explanation:** Prints goodbye message and breaks out of the while loop, ending the function.

```python
        if not user_input:
```
**Explanation:** Checks if input is empty (user just pressed Enter). Empty strings are "falsy" so `not ""` is True.

```python
            print("‚ö†Ô∏è  Please enter a message\n")
            continue
```
**Explanation:** Prints warning and uses `continue` to skip the rest of this loop iteration and start over at `while True`.

```python
        try:
```
**Explanation:** Starts try-except block to handle errors gracefully during generation.

```python
            conversation_count += 1
```
**Explanation:** Increments the counter by 1. Shorthand for `conversation_count = conversation_count + 1`.

```python
            print("ü§ñ AI: ", end="")
```
**Explanation:** Prints the AI label. `end=""` prevents automatic newline, so the response appears on the same line.

```python
            response = model.generate_content(user_input)
```
**Explanation:** Generates response to the user's input.

```python
            print(response.text)
            print()
```
**Explanation:** Prints the response text. Second `print()` adds a blank line for spacing.

```python
            if conversation_count >= 3:
```
**Explanation:** After 3 messages, show an educational note. This helps students understand the limitation.

```python
                print("üí° Notice: Each response is independent. No memory of previous questions.")
                print("   We'll learn how to add memory in Module 06!\n")
```
**Explanation:** Educational messages explaining the limitation and previewing future learning. Lightbulb emoji indicates this is a tip.

```python
        except Exception as e:
```
**Explanation:** Catches any error that occurred in the try block.

```python
            print(f"‚ùå Error: {e}\n")
```
**Explanation:** Prints the error message so chat can continue even if one request fails.

---

## Section 5: Long-Form Content Generation

```python
# ============================================================================
# SECTION 5: Long-Form Content Generation
# ============================================================================
```
**Explanation:** Section separator.

```python
def long_form_generation():
```
**Explanation:** Function to demonstrate generating longer, structured content.

```python
    """
    Generate longer, structured content
    """
```
**Explanation:** Docstring.

```python
    print("\n" + "=" * 60)
    print("SECTION 5: Long-Form Content Generation")
    print("=" * 60)
```
**Explanation:** Section header.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates model instance.

```python
    # Example: Blog post generation
    print("\nüìù Generating a blog post outline...\n")
```
**Explanation:** Status message showing what's being generated.

```python
    prompt = """Write a detailed outline for a blog post about "Getting Started with AI for Beginners".

Include:
- An engaging introduction
- 5 main sections with subpoints
- A conclusion
- Keep it educational and encouraging"""
```
**Explanation:** Multi-line prompt with detailed instructions. Specifies structure (intro, 5 sections, conclusion) and tone (educational, encouraging). This guides the AI to produce a specific format.

```python
    response = model.generate_content(prompt)
```
**Explanation:** Generates the blog outline.

```python
    print("=" * 60)
    print("üìÑ Generated Blog Outline:")
    print("=" * 60)
```
**Explanation:** Prints a header to frame the generated content.

```python
    print(response.text)
```
**Explanation:** Prints the full blog outline. No truncation since this is the main deliverable.

```python
    print("=" * 60)
```
**Explanation:** Closing separator line.

---

## Section 6: Code Generation Examples

```python
# ============================================================================
# SECTION 6: Code Generation
# ============================================================================
```
**Explanation:** Section separator for code generation.

```python
def code_generation_examples():
```
**Explanation:** Function demonstrating how to use AI for code generation.

```python
    """
    Using AI to generate code
    """
```
**Explanation:** Docstring.

```python
    print("\n" + "=" * 60)
    print("SECTION 6: Code Generation")
    print("=" * 60)
```
**Explanation:** Section header.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates model.

```python
    # Example 1: Simple function
    print("\n1Ô∏è‚É£ Generate a Simple Function:\n")
```
**Explanation:** Header for first code generation example.

```python
    prompt1 = """Write a Python function that calculates the factorial of a number.
Include:
- Docstring
- Input validation
- Example usage"""
```
**Explanation:** Structured prompt for code generation. Specifies what the function should do and what quality features to include (docstring, validation, example).

```python
    print(f"üìù Request: {prompt1.split('.')[0]}...")
```
**Explanation:** Prints abbreviated version of prompt. `split('.')` splits the string at periods, `[0]` takes first sentence. The `...` indicates truncation.

```python
    response1 = model.generate_content(prompt1)
```
**Explanation:** Generates the code.

```python
    print("\nü§ñ Generated Code:")
    print("-" * 60)
```
**Explanation:** Header for the code output. Dashes create a clear boundary.

```python
    print(response1.text)
```
**Explanation:** Prints the generated code.

```python
    print("-" * 60)
```
**Explanation:** Closing boundary line.

```python
    # Example 2: Class generation
    print("\n2Ô∏è‚É£ Generate a Class:\n")
```
**Explanation:** Header for second example.

```python
    prompt2 = """Create a Python class called 'Student' with:
- Attributes: name, age, grades (list)
- Method to add a grade
- Method to calculate average grade
- Include docstrings"""
```
**Explanation:** Detailed prompt for class generation. Lists exact attributes and methods needed. This specificity ensures the AI generates exactly what's needed.

```python
    print(f"üìù Request: Create a Student class...")
```
**Explanation:** Shows abbreviated request.

```python
    response2 = model.generate_content(prompt2)
    print("\nü§ñ Generated Code:")
    print("-" * 60)
    print(response2.text)
    print("-" * 60)
```
**Explanation:** Generate, frame, and print the class code.

---

## Section 7: Practical Use Cases

```python
# ============================================================================
# SECTION 7: Practical Use Cases
# ============================================================================
```
**Explanation:** Section separator for real-world applications.

```python
def practical_use_cases():
```
**Explanation:** Function showing practical applications of text generation.

```python
    """
    Real-world applications of text generation
    """
```
**Explanation:** Docstring.

```python
    print("\n" + "=" * 60)
    print("SECTION 7: Practical Use Cases")
    print("=" * 60)
```
**Explanation:** Section header.

```python
    model = genai.GenerativeModel('gemini-pro')
```
**Explanation:** Creates model.

```python
    # Use case 1: Email writing
    print("\n1Ô∏è‚É£ Professional Email Writing:")
```
**Explanation:** First use case header.

```python
    prompt = """Write a professional email to request a meeting with a professor 
to discuss a research opportunity in machine learning. Keep it concise and polite."""
```
**Explanation:** Prompt for professional email. Specifies context (professor meeting), topic (ML research), and tone (concise, polite).

```python
    response = model.generate_content(prompt)
    print(response.text)
    print()
```
**Explanation:** Generates and prints the email.

```python
    # Use case 2: Summarization
    print("\n2Ô∏è‚É£ Text Summarization:")
```
**Explanation:** Second use case header.

```python
    long_text = """Artificial Intelligence (AI) has transformed numerous industries 
over the past decade. From healthcare to finance, education to entertainment, AI 
systems are now integral to modern operations. Machine learning algorithms can 
analyze vast amounts of data to identify patterns and make predictions. Deep 
learning, a subset of machine learning, has been particularly successful in areas 
like computer vision and natural language processing. However, the rapid adoption 
of AI also raises important ethical questions about privacy, bias, and job 
displacement that society must address."""
```
**Explanation:** Multi-line string containing a long paragraph to be summarized. This is the input text.

```python
    prompt = f"Summarize this text in 2 sentences:\n\n{long_text}"
```
**Explanation:** Creates prompt by combining instruction with the text. `\n\n` adds spacing between instruction and text. The f-string embeds the `long_text` variable.

```python
    response = model.generate_content(prompt)
```
**Explanation:** Generates the summary.

```python
    print(f"Original: {len(long_text)} characters")
```
**Explanation:** Shows original text length for comparison.

```python
    print(f"Summary: {response.text}")
    print()
```
**Explanation:** Prints the condensed summary.

```python
    # Use case 3: Translation/Rewriting
    print("\n3Ô∏è‚É£ Text Transformation:")
```
**Explanation:** Third use case header.

```python
    prompt = """Rewrite this technical sentence in simple English:
"The convolutional neural network employs hierarchical feature extraction 
to perform image classification tasks with high accuracy."
"""
```
**Explanation:** Prompt asking to simplify complex technical language. Shows the transformation use case.

```python
    response = model.generate_content(prompt)
    print(f"Simplified: {response.text}")
```
**Explanation:** Generates and prints the simplified version.

---

## Main Execution Function

```python
# ============================================================================
# MAIN EXECUTION
# ============================================================================
```
**Explanation:** Section separator for main function.

```python
def main():
```
**Explanation:** Defines the main orchestration function.

```python
    """
    Main function with menu-driven interface
    """
```
**Explanation:** Docstring describing this as a menu system.

```python
    print("\n")
    print("üéì " + "=" * 58 + " üéì")
    print("      GENERATIVE AI SESSION - MODULE 2: TEXT CHAT")
    print("üéì " + "=" * 58 + " üéì")
```
**Explanation:** Prints decorative header for the module.

```python
    menu = """
    Choose a section to run (or 'all' to run everything):
    
    1. Simple Text Generation
    2. Question Answering
    3. Prompt Engineering Techniques
    4. Interactive Single-Turn Chat
    5. Long-Form Content Generation
    6. Code Generation Examples
    7. Practical Use Cases
    
    all - Run all sections
    quit - Exit
    
    """
```
**Explanation:** Multi-line string stored in `menu` variable. Lists all available options. This makes it easy to reprint the menu.

```python
    while True:
```
**Explanation:** Infinite loop for menu system. Keeps showing menu until user quits.

```python
        print(menu)
```
**Explanation:** Prints the menu options.

```python
        choice = input("Your choice: ").strip().lower()
```
**Explanation:** Gets user input. `.strip()` removes whitespace. `.lower()` converts to lowercase so "QUIT" and "quit" both work.

```python
        if choice == 'quit' or choice == 'q':
```
**Explanation:** Checks if user wants to quit. Accepts both "quit" and "q".

```python
            print("üëã Goodbye!")
            break
```
**Explanation:** Prints goodbye and exits the loop.

```python
        elif choice == '1':
            simple_text_generation()
```
**Explanation:** If user chose '1', call the corresponding function. `elif` means "else if" - only checked if previous conditions were false.

```python
        elif choice == '2':
            question_answering()
        elif choice == '3':
            prompt_engineering_examples()
        elif choice == '4':
            interactive_single_turn()
        elif choice == '5':
            long_form_generation()
        elif choice == '6':
            code_generation_examples()
        elif choice == '7':
            practical_use_cases()
```
**Explanation:** Series of elif statements checking for choices 2-7. Each calls the corresponding function.

```python
        elif choice == 'all':
```
**Explanation:** Special option to run all sections at once.

```python
            simple_text_generation()
            question_answering()
            prompt_engineering_examples()
            long_form_generation()
            code_generation_examples()
            practical_use_cases()
```
**Explanation:** Calls most functions in sequence. Note: skips `interactive_single_turn()` since it requires user interaction.

```python
            print("\n‚úÖ All sections completed!")
            print("üí° Try section 4 separately for interactive chat")
```
**Explanation:** Success message after running all sections. Reminds user about the interactive section.

```python
        else:
            print("‚ö†Ô∏è  Invalid choice. Please try again.")
```
**Explanation:** If none of the above conditions matched, the input was invalid. Shows warning and loop continues.

---

## Script Entry Point

```python
if __name__ == "__main__":
```
**Explanation:** Checks if this script is being run directly (not imported as a module).

```python
    main()
```
**Explanation:** If run directly, call the main function to start the program.

```python
    # Teaching Questions:
    # 1. What makes a good prompt?
    # 2. How does specificity affect response quality?
    # 3. What are the limitations of single-turn conversations?
```
**Explanation:** Comments for instructors with discussion questions to assess student understanding.

---

## Summary

This module demonstrates:

1. **Multiple text generation patterns**: Questions, creative writing, explanations, code
2. **Prompt engineering techniques**: Vague vs specific, role-based, step-by-step, format specification
3. **Interactive chat**: Using `input()` for user interaction, `while True` loops
4. **String manipulation**: f-strings, slicing `[:150]`, `.split()`, `.strip()`, `.lower()`
5. **Control flow**: if/elif/else chains, try-except blocks, continue/break statements
6. **Menu-driven interface**: User-friendly navigation between sections
7. **Practical applications**: Email writing, summarization, code generation

The code is organized with clear sections, consistent patterns, and educational comments throughout.
